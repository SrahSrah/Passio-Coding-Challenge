{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Food Recognition System For Passio\n",
    "## By: Sarah Hernandez\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import cv2\n",
    "import math\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal 1: Prepare a Dataset:\n",
    "\n",
    "#### Step 1: Explore Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Foods: 144\n",
      "Not Foods: 125\n",
      "Example Food Shape: (640, 640, 3)\n",
      "Example Not Food Shape: (4032, 3024, 3)\n",
      "Example Food Shape: (480, 640, 3)\n",
      "Example Not Food Shape: (3024, 4032, 3)\n",
      "Example Food Shape: (612, 612, 3)\n",
      "Example Not Food Shape: (640, 360, 3)\n"
     ]
    }
   ],
   "source": [
    "currentDir = os.getcwd()\n",
    "foodDir = currentDir + \"/Food\"\n",
    "notFoodDir = currentDir + \"/Not Food\"\n",
    "\n",
    "foodList = os.listdir(foodDir)\n",
    "numFoods = 144 #len(foodList), entered original length before data augmentation\n",
    "\n",
    "notFoodList = os.listdir(notFoodDir)\n",
    "numNotFoods = 125 #len(notFoodList), entered original length before data augmentation\n",
    "\n",
    "print(\"Foods: \" + str(numFoods))\n",
    "print(\"Not Foods: \" + str(numNotFoods))\n",
    "\n",
    "for i in range(3):\n",
    "    testDir = foodDir + \"/\" + foodList[i]\n",
    "    img = cv2.imread(testDir)\n",
    "    print(\"Example Food Shape: \" + str(img.shape))\n",
    "    testDir2 = notFoodDir + \"/\" + notFoodList[i]\n",
    "    img2 = cv2.imread(testDir2)\n",
    "    print(\"Example Not Food Shape: \" + str(img2.shape))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have fewer than 300 images of food and not food, of various square and rectangular sizes. This is a rather small data set, so we'll augment the data using a few tricks:\n",
    "\n",
    "\n",
    "#### Step 2: Augment Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get array of directories of food and not food\n",
    "def get_image_dirs(foodList, notFoodList):\n",
    "    \n",
    "    foodDirs = []\n",
    "    for food in foodList:\n",
    "        if not food.startswith('.'):\n",
    "            foodDirs.append(foodDir + \"/\" + food)\n",
    "    \n",
    "    notFoodDirs = []\n",
    "    for notFood in notFoodList:\n",
    "        if not notFood.startswith('.'):\n",
    "            notFoodDirs.append(notFoodDir + \"/\" + notFood)\n",
    "        \n",
    "    \n",
    "    return foodDirs, notFoodDirs\n",
    "        \n",
    "\n",
    "foodDirs, notFoodDirs = get_image_dirs(foodList, notFoodList)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# First trick: flip and rotate images\n",
    "for i in range(numFoods):\n",
    "    img = cv2.imread(foodDirs[i])\n",
    "    img2 = np.fliplr(img)\n",
    "    img3 = np.flipud(img)\n",
    "    img4 = np.rot90(img)\n",
    "    cv2.imwrite(foodDir + \"/lr\" + str(i) + \".jpg\", img2)\n",
    "    cv2.imwrite(foodDir + \"/ud\" + str(i) + \".jpg\", img3)\n",
    "    cv2.imwrite(foodDir + \"/rot90\" + str(i) + \".jpg\", img4)\n",
    "    \n",
    "for i in range(numNotFoods):\n",
    "    img = cv2.imread(notFoodDirs[i])\n",
    "    img2 = np.fliplr(img)\n",
    "    img3 = np.flipud(img)\n",
    "    img4 = np.rot90(img)\n",
    "    cv2.imwrite(notFoodDir + \"/lr\" + str(i) + \".jpg\", img2)\n",
    "    cv2.imwrite(notFoodDir + \"/ud\" + str(i) + \".jpg\", img3)\n",
    "    cv2.imwrite(notFoodDir + \"/rot90\" + str(i) + \".jpg\", img4)\n",
    "    \n",
    "print(\"Completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directories created\n"
     ]
    }
   ],
   "source": [
    "# Update Food and NotFood Dirs:\n",
    "foodList = os.listdir(foodDir)\n",
    "\n",
    "notFoodList = os.listdir(notFoodDir)\n",
    "\n",
    "foodDirs, notFoodDirs = get_image_dirs(foodList, notFoodList)\n",
    "\n",
    "print(\"Directories created\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noisy Food Created\n",
      "Noisy Not Food Created\n"
     ]
    }
   ],
   "source": [
    "# Second trick: add noise to images:\n",
    "for i in range(len(foodDirs)):\n",
    "    \n",
    "    img = cv2.imread(foodDirs[i])\n",
    "    img = cv2.resize(img,(256,256))\n",
    "    row,col,ch= img.shape\n",
    "    mean = 0\n",
    "    gauss = np.random.normal(mean,30,(row,col,ch))\n",
    "    gauss = gauss.reshape(row,col,ch)\n",
    "    noisy = img + gauss\n",
    "    cv2.imwrite(foodDir + \"/noisy\" + str(i) + \".jpg\", noisy)\n",
    "\n",
    "\n",
    "print(\"Noisy Food Created\")\n",
    "\n",
    "for i in range(len(notFoodDirs)):\n",
    "    \n",
    "    img = cv2.imread(notFoodDirs[i])\n",
    "    img = cv2.resize(img,(256,256))\n",
    "    row,col,ch= img.shape\n",
    "    mean = math.ceil(255/2)\n",
    "    gauss = np.random.normal(mean,50,(row,col,ch))\n",
    "    gauss = gauss.reshape(row,col,ch)\n",
    "    noisy = img + gauss\n",
    "    cv2.imwrite(notFoodDir + \"/noisy\" + str(i) + \".jpg\", noisy)\n",
    "       \n",
    "print(\"Noisy Not Food Created\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Foods: 1152\n",
      "Number of Not Foods: 1000\n"
     ]
    }
   ],
   "source": [
    "foodList = os.listdir(foodDir)\n",
    "\n",
    "notFoodList = os.listdir(notFoodDir)\n",
    "\n",
    "foodDirs, notFoodDirs = get_image_dirs(foodList, notFoodList)\n",
    "\n",
    "print(\"Number of Foods: \" + str(len(foodDirs)))\n",
    "print(\"Number of Not Foods: \" + str(len(notFoodDirs)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've got something to work with! Next, let's generate the dataset:\n",
    "\n",
    "#### Step 3: Generate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Generated\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "class Generate_Dataset:\n",
    "    \n",
    "    def __init__(self, data_dirs):\n",
    "        self.data_dirs = data_dirs\n",
    "        self.labels = []\n",
    "        self.data_paths = []\n",
    "        self.images = []\n",
    "        \n",
    "        # Now we put all data paths in a single matrix and shuffle it: \n",
    "        self.data_paths = np.concatenate([self.data_dirs[0], self.data_dirs[1]])\n",
    "        shuffle(self.data_paths)\n",
    "        \n",
    "        #Next, generate labels:\n",
    "        for path in self.data_paths:\n",
    "            self.labels.append(self.generate_data_labels(path))\n",
    "            self.images.append(self.get_image(path))\n",
    "        \n",
    "        \n",
    "    # Returns label of specified file\n",
    "    def generate_data_labels(self, directory):\n",
    "        labels = []\n",
    "        # Because we're doing a simple binary classification, we can one-hot-encode here:\n",
    "        if \"Not\" in directory:\n",
    "            label = [1, 0]\n",
    "        else:\n",
    "            label = [0, 1]\n",
    "        \n",
    "        return label\n",
    "    \n",
    "    \n",
    "    def get_data_paths(self, startIndex, endIndex):\n",
    "        return self.data_paths[startIndex:endIndex]\n",
    "    \n",
    "    def get_data_labels(self, startIndex, endIndex):\n",
    "        return self.labels[startIndex: endIndex]\n",
    "        \n",
    "        \n",
    "    def get_image(self, path):\n",
    "        img = cv2.imread(path)\n",
    "        img = cv2.resize(img,(256,256))\n",
    "        return img\n",
    "    \n",
    "    def get_data(self):\n",
    "        return self.images, self.labels\n",
    "    \n",
    "    def get_all_dirs(self):\n",
    "        return self.data_paths\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "dirs = [foodDirs, notFoodDirs]\n",
    "dataset = Generate_Dataset(dirs)\n",
    "images, labels = dataset.get_data()\n",
    "paths = dataset.get_all_dirs()\n",
    "\n",
    "print(\"Dataset Generated\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, we've got an array of images, all scaled down to 256x256, and an array of labels that correspond to the images. But we still need to do some preprocessing:\n",
    "\n",
    "### Step 4: Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    #Returns a normalized image, x: input image data in numpy array [256, 256, 3]\n",
    "    \n",
    "    min_val = np.min(x)\n",
    "    max_val = np.max(x)\n",
    "    x = (x-min_val) / (max_val-min_val)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_helper(some_images, some_labels, some_paths, filename, isTraining = False):\n",
    "    some_images = normalize(some_images)\n",
    "    #some_images = some_images.reshape((len(some_images), 3, 256, 256))\n",
    "    \n",
    "    num_images = len(some_images)\n",
    "    \n",
    "    if not isTraining:\n",
    "        pickle.dump((some_images, some_labels, some_paths), open(filename, \"wb\"))\n",
    "    else:\n",
    "        # break training images into five batches\n",
    "        for i in range(5):\n",
    "            newFileName = filename + str(i) + \".p\"\n",
    "            first_index = int(num_images*i/5)\n",
    "            second_index = int(num_images*(i+1)/5)\n",
    "            pickle.dump((some_images[first_index:second_index], some_labels[first_index:second_index], some_paths[first_index:second_index]), open(newFileName, \"wb\"))\n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "def preprocess(currentDir):\n",
    "    \n",
    "    validation_images = []\n",
    "    validation_labels = []\n",
    "    validation_paths = []\n",
    "    test_images = []\n",
    "    test_labels = []\n",
    "    test_paths = []\n",
    "    training_images = []\n",
    "    training_labels = []\n",
    "    training_paths = []\n",
    "    # Save 10% of data for validation, and another 10% for testing:\n",
    "    first_index = int(len(images)*0.1)\n",
    "    second_index = int(len(images)*0.2)\n",
    "    \n",
    "    \n",
    "    # Save validation set:\n",
    "    validation_images.extend(images[0:first_index])\n",
    "    validation_labels.extend(labels[0:first_index])\n",
    "    validation_paths.extend(paths[0:first_index])\n",
    "    filename = currentDir + \"/\" + \"preprocess_validation.p\"\n",
    "    preprocess_helper(np.array(validation_images), np.array(validation_labels), np.array(validation_paths), filename)\n",
    "    print(\"Validation Set Saved\")\n",
    "    \n",
    "    # Save testing set:\n",
    "    test_images.extend(images[first_index:second_index])\n",
    "    test_labels.extend(labels[first_index:second_index])\n",
    "    test_paths.extend(paths[first_index:second_index])\n",
    "    filename = currentDir + \"/\" + \"preprocess_testing.p\"\n",
    "    preprocess_helper(np.array(test_images), np.array(test_labels), np.array(test_paths), filename)\n",
    "    print(\"Testing Set Saved\")\n",
    "    \n",
    "    # Save training set!\n",
    "    training_images.extend(images[second_index:])\n",
    "    training_labels.extend(labels[second_index:])\n",
    "    training_paths.extend(paths[second_index:])\n",
    "    filename = currentDir + \"/\" + \"preprocess_training\"\n",
    "    preprocess_helper(np.array(training_images), np.array(training_labels), np.array(training_paths), filename, True)\n",
    "    print(\"Training Set Saved\")\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Saved\n",
      "Testing Set Saved\n",
      "Training Set Saved\n",
      "All sets created and loaded\n"
     ]
    }
   ],
   "source": [
    "preprocess(currentDir)\n",
    "test_images, test_labels, test_paths = pickle.load(open(currentDir + \"/\" + \"preprocess_testing.p\", mode = \"rb\"))\n",
    "valid_images, valid_labels, valid_paths = pickle.load(open(currentDir + \"/\" + \"preprocess_validation.p\", mode = \"rb\"))\n",
    "\n",
    "# Split training images and labels into five batches:\n",
    "train_images = []\n",
    "train_labels = []\n",
    "train_paths = []\n",
    "for i in range(5): \n",
    "    batch_images, batch_labels, batch_paths = pickle.load(open(currentDir + \"/\" + \"preprocess_training\" + str(i) + \".p\", mode = \"rb\"))\n",
    "    train_images.append(batch_images)\n",
    "    train_labels.append(batch_labels)\n",
    "    train_paths.append(batch_paths)\n",
    "    \n",
    "print(\"All sets created and loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal 2: Implement a neural network for classifying food vs non-food\n",
    "\n",
    "#### Step 1: Prepare Model \n",
    "We will prepare the model by creating several helper functions. The first of these will help us get mini-batches as needed for training. The remaining are methods that will ech define a layer of the model: a convolutional layer, a flattening layer, a fully connected layer, or the final output layer. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create methods to get mini-batches\n",
    "def get_mini_batches(batch_size, batch_images, batch_labels, batch_paths):\n",
    "    # Returns images and labels in batches\n",
    "   \n",
    "    for start in range(0, len(batch_images), batch_size):\n",
    "        end = min(start + batch_size, len(batch_images))\n",
    "        \n",
    "        temp_img = list(batch_images[start:end])\n",
    "        \n",
    "        temp_labels = list(batch_labels[start:end])\n",
    "        \n",
    "        temp_paths = list(batch_paths[start:end])\n",
    "        \n",
    "        yield temp_img, temp_labels, temp_paths\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :-param x_tensor: TensorFlow Tensor\n",
    "    :-param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :-param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :-param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    \n",
    "    import math\n",
    "    \n",
    "    h_in =  int(x_tensor.shape[1])\n",
    "    w_in =  int(x_tensor.shape[2])\n",
    "    h = math.ceil(float(h_in - conv_strides[0] + 1) / float(conv_strides[0]))\n",
    "    w = math.ceil(float(w_in - conv_strides[1] + 1) / float(conv_strides[1]))\n",
    "    \n",
    "    \n",
    "    weights = tf.Variable(tf.random_normal([*conv_ksize, int(x_tensor.shape[3]), conv_num_outputs], mean=0.0, stddev=0.01, dtype=tf.float32))  \n",
    "    bias = tf.Variable(tf.zeros(conv_num_outputs))\n",
    "    c_strides = [1, conv_strides[0], conv_strides[1], 1]\n",
    "    p_strides = [1, pool_strides[0], pool_strides[1], 1]\n",
    "    p_ksize = [1, pool_ksize[0], pool_ksize[1], 1]\n",
    "    padding = \"SAME\"\n",
    "    \n",
    "    \n",
    "    conv = tf.nn.conv2d(tf.to_float(x_tensor), weights, c_strides, padding)\n",
    "    conv = tf.nn.bias_add(conv, bias)\n",
    "    conv = tf.nn.relu(conv)\n",
    "    conv = tf.nn.max_pool(conv, ksize = p_ksize , strides = p_strides, padding = padding)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return conv \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    \n",
    "    shape = x_tensor.get_shape().as_list()        \n",
    "    dim = np.prod(shape[1:])            \n",
    "    x2 = tf.reshape(x_tensor, [-1, dim])           # Here, -1 means \"all\"\n",
    "    \n",
    "    return x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\" \n",
    "    \n",
    "    weights = tf.Variable(tf.truncated_normal([int(x_tensor.shape[-1]), num_outputs], mean=0.0, stddev=0.01))\n",
    "\n",
    "    bias = tf.Variable(tf.zeros([num_outputs]))\n",
    "\n",
    "    layer = tf.add(tf.matmul(x_tensor, weights), bias)\n",
    "\n",
    "    layer = tf.nn.relu(layer)\n",
    "    \n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    weights = tf.Variable(tf.truncated_normal([int(x_tensor.shape[-1]), num_outputs], mean=0.0, stddev=0.01))\n",
    "\n",
    "    bias = tf.Variable(tf.zeros([num_outputs]))\n",
    "\n",
    "\n",
    "    output = tf.add(tf.matmul(x_tensor, weights), bias)\n",
    "    \n",
    "    return output \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Step 2: Build the Model\n",
    "Now, we'll combine the helper function above to create a multi-layered CNN model.\n",
    "The model is laregly based off of prior succesfull image classification models, as shown here:\n",
    "\n",
    "<img src = \"cnn_network.jpg\">\n",
    "\n",
    "\n",
    "Like in the image above, I will start off with a few convolutional layers (followed the addition of bias and the application of max pooling), followed by a flattening layer. Next will be several fully connected layers, increasing in size until the final layer, the output layer, converges into two logit outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    \n",
    "    conv_num_outputs = 2\n",
    "    conv_ksize = (3,3)\n",
    "    conv_strides = (1,1)\n",
    "    pool_ksize = (2,2)\n",
    "    pool_strides = (2,2)\n",
    "    \n",
    "    conv1 = conv2d_maxpool(x, 256, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    conv2 = conv2d_maxpool(conv1, 512, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    conv3 = conv2d_maxpool(conv1, 1024, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "\n",
    "    \n",
    "    flat = flatten(conv3)\n",
    "    \n",
    "    \n",
    "    fullycon1 = fully_conn(flat, 256)\n",
    "    fullycon2 = fully_conn(fullycon1, 512)\n",
    "    fullycon3 = fully_conn(fullycon2, 1024)\n",
    "    \n",
    "    dropout = tf.nn.dropout(fullycon3, tf.to_float(keep_prob))\n",
    "    \n",
    "    num_outputs = 2\n",
    "    outputs = output(dropout, num_outputs)\n",
    "    \n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "epochs = 101\n",
    "keep_probability = .5\n",
    "learning_rate = 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, image_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    \n",
    "    transposed_images = np.array(image_batch).transpose(0, 3, 1, 2)\n",
    "    \n",
    "    session.run(optimizer, feed_dict = {\"x:0\":transposed_images, \"y:0\": np.array(label_batch), \"keep_prob:0\": keep_probability})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, image_batch, label_batch, cost, accuracy, typeOfStat):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    \n",
    "    transposed_images = np.array(image_batch).transpose(0, 3, 1, 2)\n",
    "    \n",
    "    loss = session.run(cost, feed_dict={x: transposed_images, y: np.array(label_batch), keep_prob: 1.0})\n",
    "    acc = session.run(accuracy, feed_dict={\"x:0\": transposed_images, \"y:0\": np.array(label_batch), \"keep_prob:0\": 1.0})\n",
    "    \n",
    "    print(typeOfStat + ' Loss: {:>10.4f} Accuracy: {:.6f}'.format(loss,acc))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Step 3: Train the Model\n",
    "\n",
    "Next, we'll train the model. We'll do so by using the Adam Optimizer for gradient descent, and by shuffling each batch as we train it to increase learning. Here, we'll generate and create the tensorflow graph and run the session in one swift motion.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch Number: 0\n",
      "Epoch 0, Batch 0: \n",
      "Validation Loss:     0.6918 Accuracy: 0.544186\n",
      "Epoch 0, Batch 1: \n",
      "Validation Loss:     0.5762 Accuracy: 0.832558\n",
      "Epoch 0, Batch 2: \n",
      "Validation Loss:     0.6584 Accuracy: 0.553488\n",
      "Epoch 0, Batch 3: \n",
      "Validation Loss:     0.3982 Accuracy: 0.874419\n",
      "Epoch 0, Batch 4: \n",
      "Validation Loss:     0.2577 Accuracy: 0.869767\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.1028 Accuracy: 1.000000\n",
      "Validation Loss:     0.2577 Accuracy: 0.869767\n",
      "Epoch Number: 1\n",
      "Epoch 1, Batch 0: \n",
      "Validation Loss:     0.3320 Accuracy: 0.869767\n",
      "Epoch 1, Batch 1: \n",
      "Validation Loss:     0.2822 Accuracy: 0.841860\n",
      "Epoch 1, Batch 2: \n",
      "Validation Loss:     0.2848 Accuracy: 0.874419\n",
      "Epoch 1, Batch 3: \n",
      "Validation Loss:     0.4109 Accuracy: 0.846512\n",
      "Epoch 1, Batch 4: \n",
      "Validation Loss:     0.3269 Accuracy: 0.841860\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.1269 Accuracy: 1.000000\n",
      "Validation Loss:     0.3269 Accuracy: 0.841860\n",
      "Epoch Number: 2\n",
      "Epoch 2, Batch 0: \n",
      "Validation Loss:     0.2669 Accuracy: 0.869767\n",
      "Epoch 2, Batch 1: \n",
      "Validation Loss:     0.2919 Accuracy: 0.851163\n",
      "Epoch 2, Batch 2: \n",
      "Validation Loss:     0.3029 Accuracy: 0.869767\n",
      "Epoch 2, Batch 3: \n",
      "Validation Loss:     0.3649 Accuracy: 0.809302\n",
      "Epoch 2, Batch 4: \n",
      "Validation Loss:     0.3307 Accuracy: 0.837209\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.1940 Accuracy: 0.888889\n",
      "Validation Loss:     0.3307 Accuracy: 0.837209\n",
      "Epoch Number: 3\n",
      "Epoch 3, Batch 0: \n",
      "Validation Loss:     0.2612 Accuracy: 0.874419\n",
      "Epoch 3, Batch 1: \n",
      "Validation Loss:     0.2887 Accuracy: 0.865116\n",
      "Epoch 3, Batch 2: \n",
      "Validation Loss:     0.2313 Accuracy: 0.874419\n",
      "Epoch 3, Batch 3: \n",
      "Validation Loss:     0.4932 Accuracy: 0.781395\n",
      "Epoch 3, Batch 4: \n",
      "Validation Loss:     0.3460 Accuracy: 0.827907\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.1120 Accuracy: 0.888889\n",
      "Validation Loss:     0.3460 Accuracy: 0.827907\n",
      "Epoch Number: 4\n",
      "Epoch 4, Batch 0: \n",
      "Validation Loss:     0.2989 Accuracy: 0.841860\n",
      "Epoch 4, Batch 1: \n",
      "Validation Loss:     0.2195 Accuracy: 0.865116\n",
      "Epoch 4, Batch 2: \n",
      "Validation Loss:     0.3015 Accuracy: 0.865116\n",
      "Epoch 4, Batch 3: \n",
      "Validation Loss:     0.3728 Accuracy: 0.865116\n",
      "Epoch 4, Batch 4: \n",
      "Validation Loss:     0.3091 Accuracy: 0.846512\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0706 Accuracy: 1.000000\n",
      "Validation Loss:     0.3091 Accuracy: 0.846512\n",
      "Epoch Number: 5\n",
      "Epoch 5, Batch 0: \n",
      "Validation Loss:     0.2264 Accuracy: 0.879070\n",
      "Epoch 5, Batch 1: \n",
      "Validation Loss:     0.2570 Accuracy: 0.879070\n",
      "Epoch 5, Batch 2: \n",
      "Validation Loss:     0.3181 Accuracy: 0.841860\n",
      "Epoch 5, Batch 3: \n",
      "Validation Loss:     0.3246 Accuracy: 0.860465\n",
      "Epoch 5, Batch 4: \n",
      "Validation Loss:     0.3025 Accuracy: 0.855814\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0219 Accuracy: 1.000000\n",
      "Validation Loss:     0.3025 Accuracy: 0.855814\n",
      "Epoch Number: 6\n",
      "Epoch 6, Batch 0: \n",
      "Validation Loss:     0.2299 Accuracy: 0.869767\n",
      "Epoch 6, Batch 1: \n",
      "Validation Loss:     0.2603 Accuracy: 0.865116\n",
      "Epoch 6, Batch 2: \n",
      "Validation Loss:     0.4657 Accuracy: 0.869767\n",
      "Epoch 6, Batch 3: \n",
      "Validation Loss:     0.3656 Accuracy: 0.837209\n",
      "Epoch 6, Batch 4: \n",
      "Validation Loss:     0.2349 Accuracy: 0.888372\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.1459 Accuracy: 1.000000\n",
      "Validation Loss:     0.2349 Accuracy: 0.888372\n",
      "Epoch Number: 7\n",
      "Epoch 7, Batch 0: \n",
      "Validation Loss:     0.3534 Accuracy: 0.823256\n",
      "Epoch 7, Batch 1: \n",
      "Validation Loss:     0.2373 Accuracy: 0.897674\n",
      "Epoch 7, Batch 2: \n",
      "Validation Loss:     0.3166 Accuracy: 0.897674\n",
      "Epoch 7, Batch 3: \n",
      "Validation Loss:     0.2570 Accuracy: 0.916279\n",
      "Epoch 7, Batch 4: \n",
      "Validation Loss:     0.2793 Accuracy: 0.874419\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0118 Accuracy: 1.000000\n",
      "Validation Loss:     0.2793 Accuracy: 0.874419\n",
      "Epoch Number: 8\n",
      "Epoch 8, Batch 0: \n",
      "Validation Loss:     0.2343 Accuracy: 0.888372\n",
      "Epoch 8, Batch 1: \n",
      "Validation Loss:     0.3072 Accuracy: 0.869767\n",
      "Epoch 8, Batch 2: \n",
      "Validation Loss:     0.3760 Accuracy: 0.874419\n",
      "Epoch 8, Batch 3: \n",
      "Validation Loss:     0.3308 Accuracy: 0.832558\n",
      "Epoch 8, Batch 4: \n",
      "Validation Loss:     0.2517 Accuracy: 0.888372\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0362 Accuracy: 1.000000\n",
      "Validation Loss:     0.2517 Accuracy: 0.888372\n",
      "Epoch Number: 9\n",
      "Epoch 9, Batch 0: \n",
      "Validation Loss:     0.3091 Accuracy: 0.865116\n",
      "Epoch 9, Batch 1: \n",
      "Validation Loss:     0.3910 Accuracy: 0.837209\n",
      "Epoch 9, Batch 2: \n",
      "Validation Loss:     0.2853 Accuracy: 0.883721\n",
      "Epoch 9, Batch 3: \n",
      "Validation Loss:     0.2731 Accuracy: 0.906977\n",
      "Epoch 9, Batch 4: \n",
      "Validation Loss:     0.2902 Accuracy: 0.906977\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0295 Accuracy: 1.000000\n",
      "Validation Loss:     0.2902 Accuracy: 0.906977\n",
      "Epoch Number: 10\n",
      "Epoch 10, Batch 0: \n",
      "Validation Loss:     0.2693 Accuracy: 0.851163\n",
      "Epoch 10, Batch 1: \n",
      "Validation Loss:     0.2574 Accuracy: 0.874419\n",
      "Epoch 10, Batch 2: \n",
      "Validation Loss:     0.3293 Accuracy: 0.846512\n",
      "Epoch 10, Batch 3: \n",
      "Validation Loss:     0.2499 Accuracy: 0.911628\n",
      "Epoch 10, Batch 4: \n",
      "Validation Loss:     0.2383 Accuracy: 0.888372\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.1146 Accuracy: 1.000000\n",
      "Validation Loss:     0.2383 Accuracy: 0.888372\n",
      "Epoch Number: 11\n",
      "Epoch 11, Batch 0: \n",
      "Validation Loss:     0.2297 Accuracy: 0.883721\n",
      "Epoch 11, Batch 1: \n",
      "Validation Loss:     0.3254 Accuracy: 0.851163\n",
      "Epoch 11, Batch 2: \n",
      "Validation Loss:     0.2855 Accuracy: 0.883721\n",
      "Epoch 11, Batch 3: \n",
      "Validation Loss:     0.2523 Accuracy: 0.888372\n",
      "Epoch 11, Batch 4: \n",
      "Validation Loss:     0.2957 Accuracy: 0.893023\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0289 Accuracy: 1.000000\n",
      "Validation Loss:     0.2957 Accuracy: 0.893023\n",
      "Epoch Number: 12\n",
      "Epoch 12, Batch 0: \n",
      "Validation Loss:     0.2581 Accuracy: 0.879070\n",
      "Epoch 12, Batch 1: \n",
      "Validation Loss:     0.3278 Accuracy: 0.841860\n",
      "Epoch 12, Batch 2: \n",
      "Validation Loss:     0.6724 Accuracy: 0.916279\n",
      "Epoch 12, Batch 3: \n",
      "Validation Loss:     0.2278 Accuracy: 0.883721\n",
      "Epoch 12, Batch 4: \n",
      "Validation Loss:     0.2619 Accuracy: 0.902326\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0074 Accuracy: 1.000000\n",
      "Validation Loss:     0.2619 Accuracy: 0.902326\n",
      "Epoch Number: 13\n",
      "Epoch 13, Batch 0: \n",
      "Validation Loss:     0.3549 Accuracy: 0.883721\n",
      "Epoch 13, Batch 1: \n",
      "Validation Loss:     0.2802 Accuracy: 0.855814\n",
      "Epoch 13, Batch 2: \n",
      "Validation Loss:     0.2385 Accuracy: 0.893023\n",
      "Epoch 13, Batch 3: \n",
      "Validation Loss:     0.2662 Accuracy: 0.874419\n",
      "Epoch 13, Batch 4: \n",
      "Validation Loss:     0.2808 Accuracy: 0.860465\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0399 Accuracy: 1.000000\n",
      "Validation Loss:     0.2808 Accuracy: 0.860465\n",
      "Epoch Number: 14\n",
      "Epoch 14, Batch 0: \n",
      "Validation Loss:     0.2393 Accuracy: 0.916279\n",
      "Epoch 14, Batch 1: \n",
      "Validation Loss:     0.3451 Accuracy: 0.860465\n",
      "Epoch 14, Batch 2: \n",
      "Validation Loss:     0.2695 Accuracy: 0.897674\n",
      "Epoch 14, Batch 3: \n",
      "Validation Loss:     0.2694 Accuracy: 0.869767\n",
      "Epoch 14, Batch 4: \n",
      "Validation Loss:     0.3700 Accuracy: 0.897674\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0035 Accuracy: 1.000000\n",
      "Validation Loss:     0.3700 Accuracy: 0.897674\n",
      "Epoch Number: 15\n",
      "Epoch 15, Batch 0: \n",
      "Validation Loss:     0.2846 Accuracy: 0.902326\n",
      "Epoch 15, Batch 1: \n",
      "Validation Loss:     0.2583 Accuracy: 0.893023\n",
      "Epoch 15, Batch 2: \n",
      "Validation Loss:     0.3242 Accuracy: 0.902326\n",
      "Epoch 15, Batch 3: \n",
      "Validation Loss:     0.3851 Accuracy: 0.874419\n",
      "Epoch 15, Batch 4: \n",
      "Validation Loss:     0.2944 Accuracy: 0.879070\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0249 Accuracy: 1.000000\n",
      "Validation Loss:     0.2944 Accuracy: 0.879070\n",
      "Epoch Number: 16\n",
      "Epoch 16, Batch 0: \n",
      "Validation Loss:     0.2711 Accuracy: 0.897674\n",
      "Epoch 16, Batch 1: \n",
      "Validation Loss:     0.2460 Accuracy: 0.893023\n",
      "Epoch 16, Batch 2: \n",
      "Validation Loss:     0.3184 Accuracy: 0.869767\n",
      "Epoch 16, Batch 3: \n",
      "Validation Loss:     0.3262 Accuracy: 0.879070\n",
      "Epoch 16, Batch 4: \n",
      "Validation Loss:     0.2687 Accuracy: 0.897674\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0060 Accuracy: 1.000000\n",
      "Validation Loss:     0.2687 Accuracy: 0.897674\n",
      "Epoch Number: 17\n",
      "Epoch 17, Batch 0: \n",
      "Validation Loss:     0.3230 Accuracy: 0.874419\n",
      "Epoch 17, Batch 1: \n",
      "Validation Loss:     0.3809 Accuracy: 0.851163\n",
      "Epoch 17, Batch 2: \n",
      "Validation Loss:     0.9343 Accuracy: 0.883721\n",
      "Epoch 17, Batch 3: \n",
      "Validation Loss:     0.2550 Accuracy: 0.883721\n",
      "Epoch 17, Batch 4: \n",
      "Validation Loss:     0.4660 Accuracy: 0.888372\n",
      "End of Epoch Losses:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:     0.0169 Accuracy: 1.000000\n",
      "Validation Loss:     0.4660 Accuracy: 0.888372\n",
      "Epoch Number: 18\n",
      "Epoch 18, Batch 0: \n",
      "Validation Loss:     0.3161 Accuracy: 0.920930\n",
      "Epoch 18, Batch 1: \n",
      "Validation Loss:     0.3053 Accuracy: 0.883721\n",
      "Epoch 18, Batch 2: \n",
      "Validation Loss:     0.3652 Accuracy: 0.906977\n",
      "Epoch 18, Batch 3: \n",
      "Validation Loss:     0.4254 Accuracy: 0.869767\n",
      "Epoch 18, Batch 4: \n",
      "Validation Loss:     0.2626 Accuracy: 0.916279\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0402 Accuracy: 1.000000\n",
      "Validation Loss:     0.2626 Accuracy: 0.916279\n",
      "Epoch Number: 19\n",
      "Epoch 19, Batch 0: \n",
      "Validation Loss:     0.2506 Accuracy: 0.906977\n",
      "Epoch 19, Batch 1: \n",
      "Validation Loss:     0.4125 Accuracy: 0.888372\n",
      "Epoch 19, Batch 2: \n",
      "Validation Loss:     0.4014 Accuracy: 0.860465\n",
      "Epoch 19, Batch 3: \n",
      "Validation Loss:     0.2696 Accuracy: 0.897674\n",
      "Epoch 19, Batch 4: \n",
      "Validation Loss:     0.2977 Accuracy: 0.893023\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.1088 Accuracy: 1.000000\n",
      "Validation Loss:     0.2977 Accuracy: 0.893023\n",
      "Epoch Number: 20\n",
      "Epoch 20, Batch 0: \n",
      "Validation Loss:     0.2008 Accuracy: 0.925581\n",
      "Epoch 20, Batch 1: \n",
      "Validation Loss:     0.3965 Accuracy: 0.841860\n",
      "Epoch 20, Batch 2: \n",
      "Validation Loss:     0.2113 Accuracy: 0.902326\n",
      "Epoch 20, Batch 3: \n",
      "Validation Loss:     0.3065 Accuracy: 0.851163\n",
      "Epoch 20, Batch 4: \n",
      "Validation Loss:     0.2227 Accuracy: 0.897674\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0976 Accuracy: 0.888889\n",
      "Validation Loss:     0.2227 Accuracy: 0.897674\n",
      "Epoch Number: 21\n",
      "Epoch 21, Batch 0: \n",
      "Validation Loss:     0.1915 Accuracy: 0.906977\n",
      "Epoch 21, Batch 1: \n",
      "Validation Loss:     0.2620 Accuracy: 0.874419\n",
      "Epoch 21, Batch 2: \n",
      "Validation Loss:     0.2771 Accuracy: 0.888372\n",
      "Epoch 21, Batch 3: \n",
      "Validation Loss:     0.4323 Accuracy: 0.855814\n",
      "Epoch 21, Batch 4: \n",
      "Validation Loss:     0.2896 Accuracy: 0.883721\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0850 Accuracy: 1.000000\n",
      "Validation Loss:     0.2896 Accuracy: 0.883721\n",
      "Epoch Number: 22\n",
      "Epoch 22, Batch 0: \n",
      "Validation Loss:     0.2470 Accuracy: 0.906977\n",
      "Epoch 22, Batch 1: \n",
      "Validation Loss:     0.2542 Accuracy: 0.902326\n",
      "Epoch 22, Batch 2: \n",
      "Validation Loss:     0.1984 Accuracy: 0.934884\n",
      "Epoch 22, Batch 3: \n",
      "Validation Loss:     0.1856 Accuracy: 0.930233\n",
      "Epoch 22, Batch 4: \n",
      "Validation Loss:     0.2021 Accuracy: 0.934884\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0128 Accuracy: 1.000000\n",
      "Validation Loss:     0.2021 Accuracy: 0.934884\n",
      "Epoch Number: 23\n",
      "Epoch 23, Batch 0: \n",
      "Validation Loss:     0.1751 Accuracy: 0.930233\n",
      "Epoch 23, Batch 1: \n",
      "Validation Loss:     0.1720 Accuracy: 0.916279\n",
      "Epoch 23, Batch 2: \n",
      "Validation Loss:     0.1959 Accuracy: 0.925581\n",
      "Epoch 23, Batch 3: \n",
      "Validation Loss:     0.1854 Accuracy: 0.930233\n",
      "Epoch 23, Batch 4: \n",
      "Validation Loss:     0.2155 Accuracy: 0.948837\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0115 Accuracy: 1.000000\n",
      "Validation Loss:     0.2155 Accuracy: 0.948837\n",
      "Epoch Number: 24\n",
      "Epoch 24, Batch 0: \n",
      "Validation Loss:     0.1967 Accuracy: 0.934884\n",
      "Epoch 24, Batch 1: \n",
      "Validation Loss:     0.3876 Accuracy: 0.920930\n",
      "Epoch 24, Batch 2: \n",
      "Validation Loss:     0.2593 Accuracy: 0.934884\n",
      "Epoch 24, Batch 3: \n",
      "Validation Loss:     0.2901 Accuracy: 0.897674\n",
      "Epoch 24, Batch 4: \n",
      "Validation Loss:     0.2763 Accuracy: 0.925581\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0006 Accuracy: 1.000000\n",
      "Validation Loss:     0.2763 Accuracy: 0.925581\n",
      "Epoch Number: 25\n",
      "Epoch 25, Batch 0: \n",
      "Validation Loss:     0.5770 Accuracy: 0.576744\n",
      "Epoch 25, Batch 1: \n",
      "Validation Loss:     0.5974 Accuracy: 0.632558\n",
      "Epoch 25, Batch 2: \n",
      "Validation Loss:     0.4828 Accuracy: 0.786047\n",
      "Epoch 25, Batch 3: \n",
      "Validation Loss:     0.5097 Accuracy: 0.744186\n",
      "Epoch 25, Batch 4: \n",
      "Validation Loss:     0.3953 Accuracy: 0.832558\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.3078 Accuracy: 0.888889\n",
      "Validation Loss:     0.3953 Accuracy: 0.832558\n",
      "Epoch Number: 26\n",
      "Epoch 26, Batch 0: \n",
      "Validation Loss:     0.4130 Accuracy: 0.827907\n",
      "Epoch 26, Batch 1: \n",
      "Validation Loss:     0.3406 Accuracy: 0.869767\n",
      "Epoch 26, Batch 2: \n",
      "Validation Loss:     0.2787 Accuracy: 0.874419\n",
      "Epoch 26, Batch 3: \n",
      "Validation Loss:     0.3423 Accuracy: 0.837209\n",
      "Epoch 26, Batch 4: \n",
      "Validation Loss:     0.2519 Accuracy: 0.855814\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.1489 Accuracy: 1.000000\n",
      "Validation Loss:     0.2519 Accuracy: 0.855814\n",
      "Epoch Number: 27\n",
      "Epoch 27, Batch 0: \n",
      "Validation Loss:     0.2327 Accuracy: 0.879070\n",
      "Epoch 27, Batch 1: \n",
      "Validation Loss:     0.2847 Accuracy: 0.874419\n",
      "Epoch 27, Batch 2: \n",
      "Validation Loss:     0.2761 Accuracy: 0.879070\n",
      "Epoch 27, Batch 3: \n",
      "Validation Loss:     0.3716 Accuracy: 0.855814\n",
      "Epoch 27, Batch 4: \n",
      "Validation Loss:     0.2600 Accuracy: 0.855814\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.1775 Accuracy: 1.000000\n",
      "Validation Loss:     0.2600 Accuracy: 0.855814\n",
      "Epoch Number: 28\n",
      "Epoch 28, Batch 0: \n",
      "Validation Loss:     0.2678 Accuracy: 0.883721\n",
      "Epoch 28, Batch 1: \n",
      "Validation Loss:     0.2174 Accuracy: 0.902326\n",
      "Epoch 28, Batch 2: \n",
      "Validation Loss:     0.2473 Accuracy: 0.897674\n",
      "Epoch 28, Batch 3: \n",
      "Validation Loss:     0.2073 Accuracy: 0.902326\n",
      "Epoch 28, Batch 4: \n",
      "Validation Loss:     0.1896 Accuracy: 0.906977\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0316 Accuracy: 1.000000\n",
      "Validation Loss:     0.1896 Accuracy: 0.906977\n",
      "Epoch Number: 29\n",
      "Epoch 29, Batch 0: \n",
      "Validation Loss:     0.2046 Accuracy: 0.897674\n",
      "Epoch 29, Batch 1: \n",
      "Validation Loss:     0.2005 Accuracy: 0.911628\n",
      "Epoch 29, Batch 2: \n",
      "Validation Loss:     0.2397 Accuracy: 0.920930\n",
      "Epoch 29, Batch 3: \n",
      "Validation Loss:     0.3517 Accuracy: 0.841860\n",
      "Epoch 29, Batch 4: \n",
      "Validation Loss:     0.2288 Accuracy: 0.893023\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0511 Accuracy: 1.000000\n",
      "Validation Loss:     0.2288 Accuracy: 0.893023\n",
      "Epoch Number: 30\n",
      "Epoch 30, Batch 0: \n",
      "Validation Loss:     0.2086 Accuracy: 0.920930\n",
      "Epoch 30, Batch 1: \n",
      "Validation Loss:     0.1860 Accuracy: 0.916279\n",
      "Epoch 30, Batch 2: \n",
      "Validation Loss:     0.1539 Accuracy: 0.934884\n",
      "Epoch 30, Batch 3: \n",
      "Validation Loss:     0.1935 Accuracy: 0.911628\n",
      "Epoch 30, Batch 4: \n",
      "Validation Loss:     0.1870 Accuracy: 0.920930\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0382 Accuracy: 1.000000\n",
      "Validation Loss:     0.1870 Accuracy: 0.920930\n",
      "Epoch Number: 31\n",
      "Epoch 31, Batch 0: \n",
      "Validation Loss:     0.2123 Accuracy: 0.902326\n",
      "Epoch 31, Batch 1: \n",
      "Validation Loss:     0.2019 Accuracy: 0.916279\n",
      "Epoch 31, Batch 2: \n",
      "Validation Loss:     0.2313 Accuracy: 0.911628\n",
      "Epoch 31, Batch 3: \n",
      "Validation Loss:     0.2058 Accuracy: 0.906977\n",
      "Epoch 31, Batch 4: \n",
      "Validation Loss:     0.2111 Accuracy: 0.897674\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.1006 Accuracy: 1.000000\n",
      "Validation Loss:     0.2111 Accuracy: 0.897674\n",
      "Epoch Number: 32\n",
      "Epoch 32, Batch 0: \n",
      "Validation Loss:     0.1791 Accuracy: 0.930233\n",
      "Epoch 32, Batch 1: \n",
      "Validation Loss:     0.1789 Accuracy: 0.930233\n",
      "Epoch 32, Batch 2: \n",
      "Validation Loss:     0.1455 Accuracy: 0.944186\n",
      "Epoch 32, Batch 3: \n",
      "Validation Loss:     0.1643 Accuracy: 0.939535\n",
      "Epoch 32, Batch 4: \n",
      "Validation Loss:     0.1813 Accuracy: 0.920930\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.1141 Accuracy: 0.888889\n",
      "Validation Loss:     0.1813 Accuracy: 0.920930\n",
      "Epoch Number: 33\n",
      "Epoch 33, Batch 0: \n",
      "Validation Loss:     0.1372 Accuracy: 0.948837\n",
      "Epoch 33, Batch 1: \n",
      "Validation Loss:     0.1147 Accuracy: 0.962791\n",
      "Epoch 33, Batch 2: \n",
      "Validation Loss:     0.1202 Accuracy: 0.958140\n",
      "Epoch 33, Batch 3: \n",
      "Validation Loss:     0.3337 Accuracy: 0.888372\n",
      "Epoch 33, Batch 4: \n",
      "Validation Loss:     0.1593 Accuracy: 0.930233\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0635 Accuracy: 1.000000\n",
      "Validation Loss:     0.1593 Accuracy: 0.930233\n",
      "Epoch Number: 34\n",
      "Epoch 34, Batch 0: \n",
      "Validation Loss:     0.1287 Accuracy: 0.939535\n",
      "Epoch 34, Batch 1: \n",
      "Validation Loss:     0.1403 Accuracy: 0.944186\n",
      "Epoch 34, Batch 2: \n",
      "Validation Loss:     0.1510 Accuracy: 0.930233\n",
      "Epoch 34, Batch 3: \n",
      "Validation Loss:     0.1940 Accuracy: 0.925581\n",
      "Epoch 34, Batch 4: \n",
      "Validation Loss:     0.1550 Accuracy: 0.939535\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0157 Accuracy: 1.000000\n",
      "Validation Loss:     0.1550 Accuracy: 0.939535\n",
      "Epoch Number: 35\n",
      "Epoch 35, Batch 0: \n",
      "Validation Loss:     0.1705 Accuracy: 0.948837\n",
      "Epoch 35, Batch 1: \n",
      "Validation Loss:     0.1642 Accuracy: 0.948837\n",
      "Epoch 35, Batch 2: \n",
      "Validation Loss:     0.1582 Accuracy: 0.948837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35, Batch 3: \n",
      "Validation Loss:     0.1143 Accuracy: 0.948837\n",
      "Epoch 35, Batch 4: \n",
      "Validation Loss:     0.5154 Accuracy: 0.893023\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0302 Accuracy: 1.000000\n",
      "Validation Loss:     0.5154 Accuracy: 0.893023\n",
      "Epoch Number: 36\n",
      "Epoch 36, Batch 0: \n",
      "Validation Loss:     0.4219 Accuracy: 0.846512\n",
      "Epoch 36, Batch 1: \n",
      "Validation Loss:     0.2336 Accuracy: 0.906977\n",
      "Epoch 36, Batch 2: \n",
      "Validation Loss:     0.3075 Accuracy: 0.934884\n",
      "Epoch 36, Batch 3: \n",
      "Validation Loss:     0.1685 Accuracy: 0.920930\n",
      "Epoch 36, Batch 4: \n",
      "Validation Loss:     0.3214 Accuracy: 0.897674\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0371 Accuracy: 1.000000\n",
      "Validation Loss:     0.3214 Accuracy: 0.897674\n",
      "Epoch Number: 37\n",
      "Epoch 37, Batch 0: \n",
      "Validation Loss:     0.1351 Accuracy: 0.920930\n",
      "Epoch 37, Batch 1: \n",
      "Validation Loss:     0.1682 Accuracy: 0.930233\n",
      "Epoch 37, Batch 2: \n",
      "Validation Loss:     0.2190 Accuracy: 0.939535\n",
      "Epoch 37, Batch 3: \n",
      "Validation Loss:     0.1982 Accuracy: 0.925581\n",
      "Epoch 37, Batch 4: \n",
      "Validation Loss:     0.1729 Accuracy: 0.911628\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0528 Accuracy: 1.000000\n",
      "Validation Loss:     0.1729 Accuracy: 0.911628\n",
      "Epoch Number: 38\n",
      "Epoch 38, Batch 0: \n",
      "Validation Loss:     0.1694 Accuracy: 0.906977\n",
      "Epoch 38, Batch 1: \n",
      "Validation Loss:     0.2100 Accuracy: 0.906977\n",
      "Epoch 38, Batch 2: \n",
      "Validation Loss:     0.2309 Accuracy: 0.930233\n",
      "Epoch 38, Batch 3: \n",
      "Validation Loss:     0.1841 Accuracy: 0.920930\n",
      "Epoch 38, Batch 4: \n",
      "Validation Loss:     0.2159 Accuracy: 0.911628\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0421 Accuracy: 1.000000\n",
      "Validation Loss:     0.2159 Accuracy: 0.911628\n",
      "Epoch Number: 39\n",
      "Epoch 39, Batch 0: \n",
      "Validation Loss:     0.2167 Accuracy: 0.911628\n",
      "Epoch 39, Batch 1: \n",
      "Validation Loss:     0.3453 Accuracy: 0.916279\n",
      "Epoch 39, Batch 2: \n",
      "Validation Loss:     0.2431 Accuracy: 0.925581\n",
      "Epoch 39, Batch 3: \n",
      "Validation Loss:     0.1486 Accuracy: 0.934884\n",
      "Epoch 39, Batch 4: \n",
      "Validation Loss:     0.1478 Accuracy: 0.953488\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0108 Accuracy: 1.000000\n",
      "Validation Loss:     0.1478 Accuracy: 0.953488\n",
      "Epoch Number: 40\n",
      "Epoch 40, Batch 0: \n",
      "Validation Loss:     0.1644 Accuracy: 0.925581\n",
      "Epoch 40, Batch 1: \n",
      "Validation Loss:     0.5261 Accuracy: 0.911628\n",
      "Epoch 40, Batch 2: \n",
      "Validation Loss:     0.3216 Accuracy: 0.939535\n",
      "Epoch 40, Batch 3: \n",
      "Validation Loss:     0.1863 Accuracy: 0.930233\n",
      "Epoch 40, Batch 4: \n",
      "Validation Loss:     0.2500 Accuracy: 0.911628\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0256 Accuracy: 1.000000\n",
      "Validation Loss:     0.2500 Accuracy: 0.911628\n",
      "Epoch Number: 41\n",
      "Epoch 41, Batch 0: \n",
      "Validation Loss:     0.1460 Accuracy: 0.934884\n",
      "Epoch 41, Batch 1: \n",
      "Validation Loss:     0.1582 Accuracy: 0.930233\n",
      "Epoch 41, Batch 2: \n",
      "Validation Loss:     0.1957 Accuracy: 0.934884\n",
      "Epoch 41, Batch 3: \n",
      "Validation Loss:     0.2469 Accuracy: 0.925581\n",
      "Epoch 41, Batch 4: \n",
      "Validation Loss:     0.1680 Accuracy: 0.934884\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0253 Accuracy: 1.000000\n",
      "Validation Loss:     0.1680 Accuracy: 0.934884\n",
      "Epoch Number: 42\n",
      "Epoch 42, Batch 0: \n",
      "Validation Loss:     0.1963 Accuracy: 0.934884\n",
      "Epoch 42, Batch 1: \n",
      "Validation Loss:     0.1842 Accuracy: 0.930233\n",
      "Epoch 42, Batch 2: \n",
      "Validation Loss:     0.1307 Accuracy: 0.944186\n",
      "Epoch 42, Batch 3: \n",
      "Validation Loss:     0.1840 Accuracy: 0.939535\n",
      "Epoch 42, Batch 4: \n",
      "Validation Loss:     0.2047 Accuracy: 0.930233\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0014 Accuracy: 1.000000\n",
      "Validation Loss:     0.2047 Accuracy: 0.930233\n",
      "Epoch Number: 43\n",
      "Epoch 43, Batch 0: \n",
      "Validation Loss:     0.2160 Accuracy: 0.934884\n",
      "Epoch 43, Batch 1: \n",
      "Validation Loss:     0.3234 Accuracy: 0.930233\n",
      "Epoch 43, Batch 2: \n",
      "Validation Loss:     0.1650 Accuracy: 0.948837\n",
      "Epoch 43, Batch 3: \n",
      "Validation Loss:     0.2162 Accuracy: 0.934884\n",
      "Epoch 43, Batch 4: \n",
      "Validation Loss:     0.4281 Accuracy: 0.897674\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0019 Accuracy: 1.000000\n",
      "Validation Loss:     0.4281 Accuracy: 0.897674\n",
      "Epoch Number: 44\n",
      "Epoch 44, Batch 0: \n",
      "Validation Loss:     0.3481 Accuracy: 0.883721\n",
      "Epoch 44, Batch 1: \n",
      "Validation Loss:     0.1850 Accuracy: 0.925581\n",
      "Epoch 44, Batch 2: \n",
      "Validation Loss:     0.1735 Accuracy: 0.925581\n",
      "Epoch 44, Batch 3: \n",
      "Validation Loss:     0.2686 Accuracy: 0.902326\n",
      "Epoch 44, Batch 4: \n",
      "Validation Loss:     0.1450 Accuracy: 0.939535\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0569 Accuracy: 1.000000\n",
      "Validation Loss:     0.1450 Accuracy: 0.939535\n",
      "Epoch Number: 45\n",
      "Epoch 45, Batch 0: \n",
      "Validation Loss:     0.1524 Accuracy: 0.934884\n",
      "Epoch 45, Batch 1: \n",
      "Validation Loss:     0.1206 Accuracy: 0.948837\n",
      "Epoch 45, Batch 2: \n",
      "Validation Loss:     0.1273 Accuracy: 0.948837\n",
      "Epoch 45, Batch 3: \n",
      "Validation Loss:     0.1466 Accuracy: 0.953488\n",
      "Epoch 45, Batch 4: \n",
      "Validation Loss:     0.1264 Accuracy: 0.948837\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0131 Accuracy: 1.000000\n",
      "Validation Loss:     0.1264 Accuracy: 0.948837\n",
      "Epoch Number: 46\n",
      "Epoch 46, Batch 0: \n",
      "Validation Loss:     0.1283 Accuracy: 0.948837\n",
      "Epoch 46, Batch 1: \n",
      "Validation Loss:     0.1396 Accuracy: 0.939535\n",
      "Epoch 46, Batch 2: \n",
      "Validation Loss:     0.1541 Accuracy: 0.948837\n",
      "Epoch 46, Batch 3: \n",
      "Validation Loss:     0.1287 Accuracy: 0.944186\n",
      "Epoch 46, Batch 4: \n",
      "Validation Loss:     0.1591 Accuracy: 0.939535\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0099 Accuracy: 1.000000\n",
      "Validation Loss:     0.1591 Accuracy: 0.939535\n",
      "Epoch Number: 47\n",
      "Epoch 47, Batch 0: \n",
      "Validation Loss:     0.1911 Accuracy: 0.944186\n",
      "Epoch 47, Batch 1: \n",
      "Validation Loss:     0.1808 Accuracy: 0.925581\n",
      "Epoch 47, Batch 2: \n",
      "Validation Loss:     0.1857 Accuracy: 0.925581\n",
      "Epoch 47, Batch 3: \n",
      "Validation Loss:     0.1822 Accuracy: 0.948837\n",
      "Epoch 47, Batch 4: \n",
      "Validation Loss:     0.8206 Accuracy: 0.879070\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0588 Accuracy: 1.000000\n",
      "Validation Loss:     0.8206 Accuracy: 0.879070\n",
      "Epoch Number: 48\n",
      "Epoch 48, Batch 0: \n",
      "Validation Loss:     0.2282 Accuracy: 0.925581\n",
      "Epoch 48, Batch 1: \n",
      "Validation Loss:     0.2478 Accuracy: 0.911628\n",
      "Epoch 48, Batch 2: \n",
      "Validation Loss:     0.2303 Accuracy: 0.911628\n",
      "Epoch 48, Batch 3: \n",
      "Validation Loss:     0.2412 Accuracy: 0.920930\n",
      "Epoch 48, Batch 4: \n",
      "Validation Loss:     0.3139 Accuracy: 0.897674\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0020 Accuracy: 1.000000\n",
      "Validation Loss:     0.3139 Accuracy: 0.897674\n",
      "Epoch Number: 49\n",
      "Epoch 49, Batch 0: \n",
      "Validation Loss:     0.4766 Accuracy: 0.874419\n",
      "Epoch 49, Batch 1: \n",
      "Validation Loss:     0.3667 Accuracy: 0.911628\n",
      "Epoch 49, Batch 2: \n",
      "Validation Loss:     0.1776 Accuracy: 0.930233\n",
      "Epoch 49, Batch 3: \n",
      "Validation Loss:     0.2069 Accuracy: 0.911628\n",
      "Epoch 49, Batch 4: \n",
      "Validation Loss:     0.1992 Accuracy: 0.925581\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0067 Accuracy: 1.000000\n",
      "Validation Loss:     0.1992 Accuracy: 0.925581\n",
      "Epoch Number: 50\n",
      "Epoch 50, Batch 0: \n",
      "Validation Loss:     0.2001 Accuracy: 0.925581\n",
      "Epoch 50, Batch 1: \n",
      "Validation Loss:     0.2098 Accuracy: 0.920930\n",
      "Epoch 50, Batch 2: \n",
      "Validation Loss:     0.1770 Accuracy: 0.948837\n",
      "Epoch 50, Batch 3: \n",
      "Validation Loss:     0.1613 Accuracy: 0.953488\n",
      "Epoch 50, Batch 4: \n",
      "Validation Loss:     0.2983 Accuracy: 0.930233\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0016 Accuracy: 1.000000\n",
      "Validation Loss:     0.2983 Accuracy: 0.930233\n",
      "Epoch Number: 51\n",
      "Epoch 51, Batch 0: \n",
      "Validation Loss:     0.2181 Accuracy: 0.958140\n",
      "Epoch 51, Batch 1: \n",
      "Validation Loss:     0.3204 Accuracy: 0.939535\n",
      "Epoch 51, Batch 2: \n",
      "Validation Loss:     0.2184 Accuracy: 0.944186\n",
      "Epoch 51, Batch 3: \n",
      "Validation Loss:     0.1209 Accuracy: 0.953488\n",
      "Epoch 51, Batch 4: \n",
      "Validation Loss:     0.1562 Accuracy: 0.944186\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0039 Accuracy: 1.000000\n",
      "Validation Loss:     0.1562 Accuracy: 0.944186\n",
      "Epoch Number: 52\n",
      "Epoch 52, Batch 0: \n",
      "Validation Loss:     0.3120 Accuracy: 0.911628\n",
      "Epoch 52, Batch 1: \n",
      "Validation Loss:     0.1864 Accuracy: 0.934884\n",
      "Epoch 52, Batch 2: \n",
      "Validation Loss:     0.2176 Accuracy: 0.934884\n",
      "Epoch 52, Batch 3: \n",
      "Validation Loss:     0.3257 Accuracy: 0.911628\n",
      "Epoch 52, Batch 4: \n",
      "Validation Loss:     0.2339 Accuracy: 0.930233\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0013 Accuracy: 1.000000\n",
      "Validation Loss:     0.2339 Accuracy: 0.930233\n",
      "Epoch Number: 53\n",
      "Epoch 53, Batch 0: \n",
      "Validation Loss:     0.2763 Accuracy: 0.930233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53, Batch 1: \n",
      "Validation Loss:     0.2558 Accuracy: 0.920930\n",
      "Epoch 53, Batch 2: \n",
      "Validation Loss:     0.2812 Accuracy: 0.939535\n",
      "Epoch 53, Batch 3: \n",
      "Validation Loss:     0.3948 Accuracy: 0.916279\n",
      "Epoch 53, Batch 4: \n",
      "Validation Loss:     0.2280 Accuracy: 0.930233\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0021 Accuracy: 1.000000\n",
      "Validation Loss:     0.2280 Accuracy: 0.930233\n",
      "Epoch Number: 54\n",
      "Epoch 54, Batch 0: \n",
      "Validation Loss:     0.2695 Accuracy: 0.934884\n",
      "Epoch 54, Batch 1: \n",
      "Validation Loss:     0.1491 Accuracy: 0.962791\n",
      "Epoch 54, Batch 2: \n",
      "Validation Loss:     0.1852 Accuracy: 0.953488\n",
      "Epoch 54, Batch 3: \n",
      "Validation Loss:     0.2418 Accuracy: 0.930233\n",
      "Epoch 54, Batch 4: \n",
      "Validation Loss:     0.4121 Accuracy: 0.916279\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0007 Accuracy: 1.000000\n",
      "Validation Loss:     0.4121 Accuracy: 0.916279\n",
      "Epoch Number: 55\n",
      "Epoch 55, Batch 0: \n",
      "Validation Loss:     0.1806 Accuracy: 0.948837\n",
      "Epoch 55, Batch 1: \n",
      "Validation Loss:     0.2332 Accuracy: 0.939535\n",
      "Epoch 55, Batch 2: \n",
      "Validation Loss:     0.2430 Accuracy: 0.934884\n",
      "Epoch 55, Batch 3: \n",
      "Validation Loss:     0.2938 Accuracy: 0.930233\n",
      "Epoch 55, Batch 4: \n",
      "Validation Loss:     0.3419 Accuracy: 0.925581\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0017 Accuracy: 1.000000\n",
      "Validation Loss:     0.3419 Accuracy: 0.925581\n",
      "Epoch Number: 56\n",
      "Epoch 56, Batch 0: \n",
      "Validation Loss:     0.1932 Accuracy: 0.953488\n",
      "Epoch 56, Batch 1: \n",
      "Validation Loss:     0.2108 Accuracy: 0.962791\n",
      "Epoch 56, Batch 2: \n",
      "Validation Loss:     0.2119 Accuracy: 0.958140\n",
      "Epoch 56, Batch 3: \n",
      "Validation Loss:     0.3071 Accuracy: 0.934884\n",
      "Epoch 56, Batch 4: \n",
      "Validation Loss:     0.3241 Accuracy: 0.934884\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0004 Accuracy: 1.000000\n",
      "Validation Loss:     0.3241 Accuracy: 0.934884\n",
      "Epoch Number: 57\n",
      "Epoch 57, Batch 0: \n",
      "Validation Loss:     0.1815 Accuracy: 0.962791\n",
      "Epoch 57, Batch 1: \n",
      "Validation Loss:     0.3338 Accuracy: 0.930233\n",
      "Epoch 57, Batch 2: \n",
      "Validation Loss:     0.4076 Accuracy: 0.930233\n",
      "Epoch 57, Batch 3: \n",
      "Validation Loss:     0.3184 Accuracy: 0.944186\n",
      "Epoch 57, Batch 4: \n",
      "Validation Loss:     0.3942 Accuracy: 0.934884\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0000 Accuracy: 1.000000\n",
      "Validation Loss:     0.3942 Accuracy: 0.934884\n",
      "Epoch Number: 58\n",
      "Epoch 58, Batch 0: \n",
      "Validation Loss:     0.3338 Accuracy: 0.958140\n",
      "Epoch 58, Batch 1: \n",
      "Validation Loss:     0.2975 Accuracy: 0.948837\n",
      "Epoch 58, Batch 2: \n",
      "Validation Loss:     0.3180 Accuracy: 0.939535\n",
      "Epoch 58, Batch 3: \n",
      "Validation Loss:     0.3706 Accuracy: 0.944186\n",
      "Epoch 58, Batch 4: \n",
      "Validation Loss:     1.3708 Accuracy: 0.911628\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0000 Accuracy: 1.000000\n",
      "Validation Loss:     1.3708 Accuracy: 0.911628\n",
      "Epoch Number: 59\n",
      "Epoch 59, Batch 0: \n",
      "Validation Loss:     0.2152 Accuracy: 0.948837\n",
      "Epoch 59, Batch 1: \n",
      "Validation Loss:     0.2857 Accuracy: 0.930233\n",
      "Epoch 59, Batch 2: \n",
      "Validation Loss:     0.2690 Accuracy: 0.939535\n",
      "Epoch 59, Batch 3: \n",
      "Validation Loss:     0.1611 Accuracy: 0.948837\n",
      "Epoch 59, Batch 4: \n",
      "Validation Loss:     0.2666 Accuracy: 0.944186\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0002 Accuracy: 1.000000\n",
      "Validation Loss:     0.2666 Accuracy: 0.944186\n",
      "Epoch Number: 60\n",
      "Epoch 60, Batch 0: \n",
      "Validation Loss:     0.3348 Accuracy: 0.939535\n",
      "Epoch 60, Batch 1: \n",
      "Validation Loss:     0.1719 Accuracy: 0.962791\n",
      "Epoch 60, Batch 2: \n",
      "Validation Loss:     0.2892 Accuracy: 0.934884\n",
      "Epoch 60, Batch 3: \n",
      "Validation Loss:     0.2861 Accuracy: 0.944186\n",
      "Epoch 60, Batch 4: \n",
      "Validation Loss:     0.4164 Accuracy: 0.920930\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0001 Accuracy: 1.000000\n",
      "Validation Loss:     0.4164 Accuracy: 0.920930\n",
      "Epoch Number: 61\n",
      "Epoch 61, Batch 0: \n",
      "Validation Loss:     0.1666 Accuracy: 0.953488\n",
      "Epoch 61, Batch 1: \n",
      "Validation Loss:     0.2395 Accuracy: 0.944186\n",
      "Epoch 61, Batch 2: \n",
      "Validation Loss:     0.5523 Accuracy: 0.934884\n",
      "Epoch 61, Batch 3: \n",
      "Validation Loss:     0.3394 Accuracy: 0.944186\n",
      "Epoch 61, Batch 4: \n",
      "Validation Loss:     0.5118 Accuracy: 0.939535\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0041 Accuracy: 1.000000\n",
      "Validation Loss:     0.5118 Accuracy: 0.939535\n",
      "Epoch Number: 62\n",
      "Epoch 62, Batch 0: \n",
      "Validation Loss:     0.3276 Accuracy: 0.939535\n",
      "Epoch 62, Batch 1: \n",
      "Validation Loss:     0.2961 Accuracy: 0.953488\n",
      "Epoch 62, Batch 2: \n",
      "Validation Loss:     0.2374 Accuracy: 0.958140\n",
      "Epoch 62, Batch 3: \n",
      "Validation Loss:     0.2585 Accuracy: 0.934884\n",
      "Epoch 62, Batch 4: \n",
      "Validation Loss:     0.2141 Accuracy: 0.925581\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0042 Accuracy: 1.000000\n",
      "Validation Loss:     0.2141 Accuracy: 0.925581\n",
      "Epoch Number: 63\n",
      "Epoch 63, Batch 0: \n",
      "Validation Loss:     0.2871 Accuracy: 0.916279\n",
      "Epoch 63, Batch 1: \n",
      "Validation Loss:     0.2477 Accuracy: 0.944186\n",
      "Epoch 63, Batch 2: \n",
      "Validation Loss:     0.2175 Accuracy: 0.962791\n",
      "Epoch 63, Batch 3: \n",
      "Validation Loss:     0.1369 Accuracy: 0.939535\n",
      "Epoch 63, Batch 4: \n",
      "Validation Loss:     0.9398 Accuracy: 0.930233\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0033 Accuracy: 1.000000\n",
      "Validation Loss:     0.9398 Accuracy: 0.930233\n",
      "Epoch Number: 64\n",
      "Epoch 64, Batch 0: \n",
      "Validation Loss:     0.2734 Accuracy: 0.930233\n",
      "Epoch 64, Batch 1: \n",
      "Validation Loss:     0.2989 Accuracy: 0.934884\n",
      "Epoch 64, Batch 2: \n",
      "Validation Loss:     0.5951 Accuracy: 0.953488\n",
      "Epoch 64, Batch 3: \n",
      "Validation Loss:     0.1434 Accuracy: 0.948837\n",
      "Epoch 64, Batch 4: \n",
      "Validation Loss:     0.1287 Accuracy: 0.953488\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0059 Accuracy: 1.000000\n",
      "Validation Loss:     0.1287 Accuracy: 0.953488\n",
      "Epoch Number: 65\n",
      "Epoch 65, Batch 0: \n",
      "Validation Loss:     0.0982 Accuracy: 0.972093\n",
      "Epoch 65, Batch 1: \n",
      "Validation Loss:     0.0978 Accuracy: 0.976744\n",
      "Epoch 65, Batch 2: \n",
      "Validation Loss:     0.1224 Accuracy: 0.962791\n",
      "Epoch 65, Batch 3: \n",
      "Validation Loss:     0.1318 Accuracy: 0.967442\n",
      "Epoch 65, Batch 4: \n",
      "Validation Loss:     0.1779 Accuracy: 0.958140\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0055 Accuracy: 1.000000\n",
      "Validation Loss:     0.1779 Accuracy: 0.958140\n",
      "Epoch Number: 66\n",
      "Epoch 66, Batch 0: \n",
      "Validation Loss:     0.1116 Accuracy: 0.967442\n",
      "Epoch 66, Batch 1: \n",
      "Validation Loss:     0.1090 Accuracy: 0.972093\n",
      "Epoch 66, Batch 2: \n",
      "Validation Loss:     0.2000 Accuracy: 0.953488\n",
      "Epoch 66, Batch 3: \n",
      "Validation Loss:     0.1572 Accuracy: 0.972093\n",
      "Epoch 66, Batch 4: \n",
      "Validation Loss:     0.1084 Accuracy: 0.972093\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0041 Accuracy: 1.000000\n",
      "Validation Loss:     0.1084 Accuracy: 0.972093\n",
      "Epoch Number: 67\n",
      "Epoch 67, Batch 0: \n",
      "Validation Loss:     0.3511 Accuracy: 0.930233\n",
      "Epoch 67, Batch 1: \n",
      "Validation Loss:     0.1901 Accuracy: 0.953488\n",
      "Epoch 67, Batch 2: \n",
      "Validation Loss:     0.3674 Accuracy: 0.944186\n",
      "Epoch 67, Batch 3: \n",
      "Validation Loss:     0.2195 Accuracy: 0.962791\n",
      "Epoch 67, Batch 4: \n",
      "Validation Loss:     0.1701 Accuracy: 0.958140\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0316 Accuracy: 1.000000\n",
      "Validation Loss:     0.1701 Accuracy: 0.958140\n",
      "Epoch Number: 68\n",
      "Epoch 68, Batch 0: \n",
      "Validation Loss:     0.1629 Accuracy: 0.948837\n",
      "Epoch 68, Batch 1: \n",
      "Validation Loss:     0.2729 Accuracy: 0.953488\n",
      "Epoch 68, Batch 2: \n",
      "Validation Loss:     0.3234 Accuracy: 0.944186\n",
      "Epoch 68, Batch 3: \n",
      "Validation Loss:     0.2083 Accuracy: 0.958140\n",
      "Epoch 68, Batch 4: \n",
      "Validation Loss:     0.1731 Accuracy: 0.953488\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0094 Accuracy: 1.000000\n",
      "Validation Loss:     0.1731 Accuracy: 0.953488\n",
      "Epoch Number: 69\n",
      "Epoch 69, Batch 0: \n",
      "Validation Loss:     0.1119 Accuracy: 0.976744\n",
      "Epoch 69, Batch 1: \n",
      "Validation Loss:     0.2330 Accuracy: 0.948837\n",
      "Epoch 69, Batch 2: \n",
      "Validation Loss:     0.2374 Accuracy: 0.953488\n",
      "Epoch 69, Batch 3: \n",
      "Validation Loss:     0.1481 Accuracy: 0.967442\n",
      "Epoch 69, Batch 4: \n",
      "Validation Loss:     0.1330 Accuracy: 0.958140\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0349 Accuracy: 1.000000\n",
      "Validation Loss:     0.1330 Accuracy: 0.958140\n",
      "Epoch Number: 70\n",
      "Epoch 70, Batch 0: \n",
      "Validation Loss:     0.1920 Accuracy: 0.962791\n",
      "Epoch 70, Batch 1: \n",
      "Validation Loss:     0.2037 Accuracy: 0.958140\n",
      "Epoch 70, Batch 2: \n",
      "Validation Loss:     0.2151 Accuracy: 0.962791\n",
      "Epoch 70, Batch 3: \n",
      "Validation Loss:     0.5951 Accuracy: 0.920930\n",
      "Epoch 70, Batch 4: \n",
      "Validation Loss:     0.1685 Accuracy: 0.962791\n",
      "End of Epoch Losses:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:     0.0022 Accuracy: 1.000000\n",
      "Validation Loss:     0.1685 Accuracy: 0.962791\n",
      "Epoch Number: 71\n",
      "Epoch 71, Batch 0: \n",
      "Validation Loss:     0.1532 Accuracy: 0.962791\n",
      "Epoch 71, Batch 1: \n",
      "Validation Loss:     0.1868 Accuracy: 0.953488\n",
      "Epoch 71, Batch 2: \n",
      "Validation Loss:     0.1781 Accuracy: 0.953488\n",
      "Epoch 71, Batch 3: \n",
      "Validation Loss:     0.1871 Accuracy: 0.962791\n",
      "Epoch 71, Batch 4: \n",
      "Validation Loss:     0.2255 Accuracy: 0.948837\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0007 Accuracy: 1.000000\n",
      "Validation Loss:     0.2255 Accuracy: 0.948837\n",
      "Epoch Number: 72\n",
      "Epoch 72, Batch 0: \n",
      "Validation Loss:     0.1946 Accuracy: 0.972093\n",
      "Epoch 72, Batch 1: \n",
      "Validation Loss:     0.1392 Accuracy: 0.972093\n",
      "Epoch 72, Batch 2: \n",
      "Validation Loss:     0.2376 Accuracy: 0.953488\n",
      "Epoch 72, Batch 3: \n",
      "Validation Loss:     0.2308 Accuracy: 0.953488\n",
      "Epoch 72, Batch 4: \n",
      "Validation Loss:     0.1791 Accuracy: 0.939535\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0009 Accuracy: 1.000000\n",
      "Validation Loss:     0.1791 Accuracy: 0.939535\n",
      "Epoch Number: 73\n",
      "Epoch 73, Batch 0: \n",
      "Validation Loss:     0.2910 Accuracy: 0.962791\n",
      "Epoch 73, Batch 1: \n",
      "Validation Loss:     0.2013 Accuracy: 0.967442\n",
      "Epoch 73, Batch 2: \n",
      "Validation Loss:     0.3634 Accuracy: 0.948837\n",
      "Epoch 73, Batch 3: \n",
      "Validation Loss:     0.2818 Accuracy: 0.962791\n",
      "Epoch 73, Batch 4: \n",
      "Validation Loss:     0.1667 Accuracy: 0.967442\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0014 Accuracy: 1.000000\n",
      "Validation Loss:     0.1667 Accuracy: 0.967442\n",
      "Epoch Number: 74\n",
      "Epoch 74, Batch 0: \n",
      "Validation Loss:     0.1744 Accuracy: 0.967442\n",
      "Epoch 74, Batch 1: \n",
      "Validation Loss:     0.2175 Accuracy: 0.976744\n",
      "Epoch 74, Batch 2: \n",
      "Validation Loss:     0.3905 Accuracy: 0.948837\n",
      "Epoch 74, Batch 3: \n",
      "Validation Loss:     0.3027 Accuracy: 0.958140\n",
      "Epoch 74, Batch 4: \n",
      "Validation Loss:     0.2732 Accuracy: 0.944186\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0003 Accuracy: 1.000000\n",
      "Validation Loss:     0.2732 Accuracy: 0.944186\n",
      "Epoch Number: 75\n",
      "Epoch 75, Batch 0: \n",
      "Validation Loss:     0.2866 Accuracy: 0.953488\n",
      "Epoch 75, Batch 1: \n",
      "Validation Loss:     0.3922 Accuracy: 0.911628\n",
      "Epoch 75, Batch 2: \n",
      "Validation Loss:     0.3166 Accuracy: 0.944186\n",
      "Epoch 75, Batch 3: \n",
      "Validation Loss:     0.1387 Accuracy: 0.948837\n",
      "Epoch 75, Batch 4: \n",
      "Validation Loss:     0.2654 Accuracy: 0.930233\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0212 Accuracy: 1.000000\n",
      "Validation Loss:     0.2654 Accuracy: 0.930233\n",
      "Epoch Number: 76\n",
      "Epoch 76, Batch 0: \n",
      "Validation Loss:     0.1929 Accuracy: 0.948837\n",
      "Epoch 76, Batch 1: \n",
      "Validation Loss:     0.2342 Accuracy: 0.962791\n",
      "Epoch 76, Batch 2: \n",
      "Validation Loss:     0.2073 Accuracy: 0.958140\n",
      "Epoch 76, Batch 3: \n",
      "Validation Loss:     0.2150 Accuracy: 0.962791\n",
      "Epoch 76, Batch 4: \n",
      "Validation Loss:     0.2119 Accuracy: 0.958140\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0014 Accuracy: 1.000000\n",
      "Validation Loss:     0.2119 Accuracy: 0.958140\n",
      "Epoch Number: 77\n",
      "Epoch 77, Batch 0: \n",
      "Validation Loss:     0.2048 Accuracy: 0.958140\n",
      "Epoch 77, Batch 1: \n",
      "Validation Loss:     0.2072 Accuracy: 0.962791\n",
      "Epoch 77, Batch 2: \n",
      "Validation Loss:     0.3975 Accuracy: 0.934884\n",
      "Epoch 77, Batch 3: \n",
      "Validation Loss:     0.3932 Accuracy: 0.958140\n",
      "Epoch 77, Batch 4: \n",
      "Validation Loss:     0.4820 Accuracy: 0.962791\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0014 Accuracy: 1.000000\n",
      "Validation Loss:     0.4820 Accuracy: 0.962791\n",
      "Epoch Number: 78\n",
      "Epoch 78, Batch 0: \n",
      "Validation Loss:     0.5707 Accuracy: 0.962791\n",
      "Epoch 78, Batch 1: \n",
      "Validation Loss:     0.4255 Accuracy: 0.967442\n",
      "Epoch 78, Batch 2: \n",
      "Validation Loss:     0.4051 Accuracy: 0.967442\n",
      "Epoch 78, Batch 3: \n",
      "Validation Loss:     0.4393 Accuracy: 0.967442\n",
      "Epoch 78, Batch 4: \n",
      "Validation Loss:     0.4967 Accuracy: 0.962791\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0007 Accuracy: 1.000000\n",
      "Validation Loss:     0.4967 Accuracy: 0.962791\n",
      "Epoch Number: 79\n",
      "Epoch 79, Batch 0: \n",
      "Validation Loss:     0.4824 Accuracy: 0.962791\n",
      "Epoch 79, Batch 1: \n",
      "Validation Loss:     0.6684 Accuracy: 0.939535\n",
      "Epoch 79, Batch 2: \n",
      "Validation Loss:     0.7397 Accuracy: 0.827907\n",
      "Epoch 79, Batch 3: \n",
      "Validation Loss:     0.3143 Accuracy: 0.874419\n",
      "Epoch 79, Batch 4: \n",
      "Validation Loss:     0.2455 Accuracy: 0.925581\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0467 Accuracy: 1.000000\n",
      "Validation Loss:     0.2455 Accuracy: 0.925581\n",
      "Epoch Number: 80\n",
      "Epoch 80, Batch 0: \n",
      "Validation Loss:     0.2518 Accuracy: 0.911628\n",
      "Epoch 80, Batch 1: \n",
      "Validation Loss:     0.2497 Accuracy: 0.930233\n",
      "Epoch 80, Batch 2: \n",
      "Validation Loss:     0.2187 Accuracy: 0.930233\n",
      "Epoch 80, Batch 3: \n",
      "Validation Loss:     0.1932 Accuracy: 0.916279\n",
      "Epoch 80, Batch 4: \n",
      "Validation Loss:     0.5456 Accuracy: 0.944186\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0400 Accuracy: 1.000000\n",
      "Validation Loss:     0.5456 Accuracy: 0.944186\n",
      "Epoch Number: 81\n",
      "Epoch 81, Batch 0: \n",
      "Validation Loss:     0.1783 Accuracy: 0.934884\n",
      "Epoch 81, Batch 1: \n",
      "Validation Loss:     0.5169 Accuracy: 0.930233\n",
      "Epoch 81, Batch 2: \n",
      "Validation Loss:     0.3267 Accuracy: 0.934884\n",
      "Epoch 81, Batch 3: \n",
      "Validation Loss:     0.7330 Accuracy: 0.934884\n",
      "Epoch 81, Batch 4: \n",
      "Validation Loss:     0.3843 Accuracy: 0.916279\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0583 Accuracy: 1.000000\n",
      "Validation Loss:     0.3843 Accuracy: 0.916279\n",
      "Epoch Number: 82\n",
      "Epoch 82, Batch 0: \n",
      "Validation Loss:     0.2960 Accuracy: 0.906977\n",
      "Epoch 82, Batch 1: \n",
      "Validation Loss:     0.1775 Accuracy: 0.944186\n",
      "Epoch 82, Batch 2: \n",
      "Validation Loss:     0.3761 Accuracy: 0.939535\n",
      "Epoch 82, Batch 3: \n",
      "Validation Loss:     0.3292 Accuracy: 0.944186\n",
      "Epoch 82, Batch 4: \n",
      "Validation Loss:     0.5017 Accuracy: 0.930233\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0007 Accuracy: 1.000000\n",
      "Validation Loss:     0.5017 Accuracy: 0.930233\n",
      "Epoch Number: 83\n",
      "Epoch 83, Batch 0: \n",
      "Validation Loss:     0.3845 Accuracy: 0.939535\n",
      "Epoch 83, Batch 1: \n",
      "Validation Loss:     0.4254 Accuracy: 0.934884\n",
      "Epoch 83, Batch 2: \n",
      "Validation Loss:     0.7425 Accuracy: 0.925581\n",
      "Epoch 83, Batch 3: \n",
      "Validation Loss:     0.6571 Accuracy: 0.925581\n",
      "Epoch 83, Batch 4: \n",
      "Validation Loss:     0.5390 Accuracy: 0.944186\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0002 Accuracy: 1.000000\n",
      "Validation Loss:     0.5390 Accuracy: 0.944186\n",
      "Epoch Number: 84\n",
      "Epoch 84, Batch 0: \n",
      "Validation Loss:     0.4939 Accuracy: 0.939535\n",
      "Epoch 84, Batch 1: \n",
      "Validation Loss:     0.3642 Accuracy: 0.953488\n",
      "Epoch 84, Batch 2: \n",
      "Validation Loss:     0.5223 Accuracy: 0.958140\n",
      "Epoch 84, Batch 3: \n",
      "Validation Loss:     0.5566 Accuracy: 0.953488\n",
      "Epoch 84, Batch 4: \n",
      "Validation Loss:     0.5310 Accuracy: 0.958140\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0002 Accuracy: 1.000000\n",
      "Validation Loss:     0.5310 Accuracy: 0.958140\n",
      "Epoch Number: 85\n",
      "Epoch 85, Batch 0: \n",
      "Validation Loss:     0.5183 Accuracy: 0.958140\n",
      "Epoch 85, Batch 1: \n",
      "Validation Loss:     0.4453 Accuracy: 0.958140\n",
      "Epoch 85, Batch 2: \n",
      "Validation Loss:     0.4575 Accuracy: 0.962791\n",
      "Epoch 85, Batch 3: \n",
      "Validation Loss:     0.5387 Accuracy: 0.953488\n",
      "Epoch 85, Batch 4: \n",
      "Validation Loss:     0.3492 Accuracy: 0.958140\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0090 Accuracy: 1.000000\n",
      "Validation Loss:     0.3492 Accuracy: 0.958140\n",
      "Epoch Number: 86\n",
      "Epoch 86, Batch 0: \n",
      "Validation Loss:     0.3217 Accuracy: 0.958140\n",
      "Epoch 86, Batch 1: \n",
      "Validation Loss:     0.6633 Accuracy: 0.934884\n",
      "Epoch 86, Batch 2: \n",
      "Validation Loss:     0.4663 Accuracy: 0.967442\n",
      "Epoch 86, Batch 3: \n",
      "Validation Loss:     0.4828 Accuracy: 0.967442\n",
      "Epoch 86, Batch 4: \n",
      "Validation Loss:     0.4378 Accuracy: 0.948837\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0003 Accuracy: 1.000000\n",
      "Validation Loss:     0.4378 Accuracy: 0.948837\n",
      "Epoch Number: 87\n",
      "Epoch 87, Batch 0: \n",
      "Validation Loss:     0.5214 Accuracy: 0.958140\n",
      "Epoch 87, Batch 1: \n",
      "Validation Loss:     0.5156 Accuracy: 0.958140\n",
      "Epoch 87, Batch 2: \n",
      "Validation Loss:     0.5481 Accuracy: 0.958140\n",
      "Epoch 87, Batch 3: \n",
      "Validation Loss:     0.5462 Accuracy: 0.962791\n",
      "Epoch 87, Batch 4: \n",
      "Validation Loss:     0.5551 Accuracy: 0.958140\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0000 Accuracy: 1.000000\n",
      "Validation Loss:     0.5551 Accuracy: 0.958140\n",
      "Epoch Number: 88\n",
      "Epoch 88, Batch 0: \n",
      "Validation Loss:     0.5503 Accuracy: 0.953488\n",
      "Epoch 88, Batch 1: \n",
      "Validation Loss:     0.5348 Accuracy: 0.958140\n",
      "Epoch 88, Batch 2: \n",
      "Validation Loss:     0.5493 Accuracy: 0.962791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88, Batch 3: \n",
      "Validation Loss:     0.5597 Accuracy: 0.962791\n",
      "Epoch 88, Batch 4: \n",
      "Validation Loss:     0.5696 Accuracy: 0.967442\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0000 Accuracy: 1.000000\n",
      "Validation Loss:     0.5696 Accuracy: 0.967442\n",
      "Epoch Number: 89\n",
      "Epoch 89, Batch 0: \n",
      "Validation Loss:     0.5765 Accuracy: 0.967442\n",
      "Epoch 89, Batch 1: \n",
      "Validation Loss:     0.5862 Accuracy: 0.967442\n",
      "Epoch 89, Batch 2: \n",
      "Validation Loss:     0.5951 Accuracy: 0.967442\n",
      "Epoch 89, Batch 3: \n",
      "Validation Loss:     0.5903 Accuracy: 0.967442\n",
      "Epoch 89, Batch 4: \n",
      "Validation Loss:     0.5965 Accuracy: 0.967442\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0000 Accuracy: 1.000000\n",
      "Validation Loss:     0.5965 Accuracy: 0.967442\n",
      "Epoch Number: 90\n",
      "Epoch 90, Batch 0: \n",
      "Validation Loss:     0.5996 Accuracy: 0.967442\n",
      "Epoch 90, Batch 1: \n",
      "Validation Loss:     0.6114 Accuracy: 0.962791\n",
      "Epoch 90, Batch 2: \n",
      "Validation Loss:     0.6214 Accuracy: 0.972093\n",
      "Epoch 90, Batch 3: \n",
      "Validation Loss:     0.6333 Accuracy: 0.972093\n",
      "Epoch 90, Batch 4: \n",
      "Validation Loss:     0.6423 Accuracy: 0.958140\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0000 Accuracy: 1.000000\n",
      "Validation Loss:     0.6423 Accuracy: 0.958140\n",
      "Epoch Number: 91\n",
      "Epoch 91, Batch 0: \n",
      "Validation Loss:     0.6445 Accuracy: 0.958140\n",
      "Epoch 91, Batch 1: \n",
      "Validation Loss:     0.6599 Accuracy: 0.958140\n",
      "Epoch 91, Batch 2: \n",
      "Validation Loss:     0.6711 Accuracy: 0.958140\n",
      "Epoch 91, Batch 3: \n",
      "Validation Loss:     0.6785 Accuracy: 0.958140\n",
      "Epoch 91, Batch 4: \n",
      "Validation Loss:     0.6848 Accuracy: 0.958140\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0000 Accuracy: 1.000000\n",
      "Validation Loss:     0.6848 Accuracy: 0.958140\n",
      "Epoch Number: 92\n",
      "Epoch 92, Batch 0: \n",
      "Validation Loss:     0.6874 Accuracy: 0.958140\n",
      "Epoch 92, Batch 1: \n",
      "Validation Loss:     0.6965 Accuracy: 0.958140\n",
      "Epoch 92, Batch 2: \n",
      "Validation Loss:     0.7092 Accuracy: 0.958140\n",
      "Epoch 92, Batch 3: \n",
      "Validation Loss:     0.7172 Accuracy: 0.958140\n",
      "Epoch 92, Batch 4: \n",
      "Validation Loss:     0.7202 Accuracy: 0.958140\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0000 Accuracy: 1.000000\n",
      "Validation Loss:     0.7202 Accuracy: 0.958140\n",
      "Epoch Number: 93\n",
      "Epoch 93, Batch 0: \n",
      "Validation Loss:     0.7269 Accuracy: 0.958140\n",
      "Epoch 93, Batch 1: \n",
      "Validation Loss:     0.7370 Accuracy: 0.958140\n",
      "Epoch 93, Batch 2: \n",
      "Validation Loss:     0.7431 Accuracy: 0.958140\n",
      "Epoch 93, Batch 3: \n",
      "Validation Loss:     0.7506 Accuracy: 0.958140\n",
      "Epoch 93, Batch 4: \n",
      "Validation Loss:     0.7593 Accuracy: 0.958140\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0000 Accuracy: 1.000000\n",
      "Validation Loss:     0.7593 Accuracy: 0.958140\n",
      "Epoch Number: 94\n",
      "Epoch 94, Batch 0: \n",
      "Validation Loss:     0.7634 Accuracy: 0.958140\n",
      "Epoch 94, Batch 1: \n",
      "Validation Loss:     0.7707 Accuracy: 0.958140\n",
      "Epoch 94, Batch 2: \n",
      "Validation Loss:     0.7954 Accuracy: 0.958140\n",
      "Epoch 94, Batch 3: \n",
      "Validation Loss:     0.7902 Accuracy: 0.962791\n",
      "Epoch 94, Batch 4: \n",
      "Validation Loss:     0.7868 Accuracy: 0.967442\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0000 Accuracy: 1.000000\n",
      "Validation Loss:     0.7868 Accuracy: 0.967442\n",
      "Epoch Number: 95\n",
      "Epoch 95, Batch 0: \n",
      "Validation Loss:     0.7886 Accuracy: 0.967442\n",
      "Epoch 95, Batch 1: \n",
      "Validation Loss:     0.7981 Accuracy: 0.962791\n",
      "Epoch 95, Batch 2: \n",
      "Validation Loss:     0.8181 Accuracy: 0.958140\n",
      "Epoch 95, Batch 3: \n",
      "Validation Loss:     0.8268 Accuracy: 0.958140\n",
      "Epoch 95, Batch 4: \n",
      "Validation Loss:     0.8327 Accuracy: 0.958140\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0000 Accuracy: 1.000000\n",
      "Validation Loss:     0.8327 Accuracy: 0.958140\n",
      "Epoch Number: 96\n",
      "Epoch 96, Batch 0: \n",
      "Validation Loss:     0.8378 Accuracy: 0.958140\n",
      "Epoch 96, Batch 1: \n",
      "Validation Loss:     0.8438 Accuracy: 0.958140\n",
      "Epoch 96, Batch 2: \n",
      "Validation Loss:     0.8510 Accuracy: 0.958140\n",
      "Epoch 96, Batch 3: \n",
      "Validation Loss:     0.8618 Accuracy: 0.958140\n",
      "Epoch 96, Batch 4: \n",
      "Validation Loss:     0.8679 Accuracy: 0.958140\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0000 Accuracy: 1.000000\n",
      "Validation Loss:     0.8679 Accuracy: 0.958140\n",
      "Epoch Number: 97\n",
      "Epoch 97, Batch 0: \n",
      "Validation Loss:     0.8700 Accuracy: 0.958140\n",
      "Epoch 97, Batch 1: \n",
      "Validation Loss:     0.8773 Accuracy: 0.958140\n",
      "Epoch 97, Batch 2: \n",
      "Validation Loss:     0.8803 Accuracy: 0.958140\n",
      "Epoch 97, Batch 3: \n",
      "Validation Loss:     0.8888 Accuracy: 0.958140\n",
      "Epoch 97, Batch 4: \n",
      "Validation Loss:     0.8941 Accuracy: 0.958140\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0000 Accuracy: 1.000000\n",
      "Validation Loss:     0.8941 Accuracy: 0.958140\n",
      "Epoch Number: 98\n",
      "Epoch 98, Batch 0: \n",
      "Validation Loss:     0.8354 Accuracy: 0.958140\n",
      "Epoch 98, Batch 1: \n",
      "Validation Loss:     0.8438 Accuracy: 0.948837\n",
      "Epoch 98, Batch 2: \n",
      "Validation Loss:     0.8658 Accuracy: 0.948837\n",
      "Epoch 98, Batch 3: \n",
      "Validation Loss:     0.8836 Accuracy: 0.948837\n",
      "Epoch 98, Batch 4: \n",
      "Validation Loss:     0.8867 Accuracy: 0.948837\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0000 Accuracy: 1.000000\n",
      "Validation Loss:     0.8867 Accuracy: 0.948837\n",
      "Epoch Number: 99\n",
      "Epoch 99, Batch 0: \n",
      "Validation Loss:     0.8899 Accuracy: 0.948837\n",
      "Epoch 99, Batch 1: \n",
      "Validation Loss:     0.8941 Accuracy: 0.948837\n",
      "Epoch 99, Batch 2: \n",
      "Validation Loss:     0.9037 Accuracy: 0.948837\n",
      "Epoch 99, Batch 3: \n",
      "Validation Loss:     0.9120 Accuracy: 0.948837\n",
      "Epoch 99, Batch 4: \n",
      "Validation Loss:     0.9156 Accuracy: 0.948837\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0000 Accuracy: 1.000000\n",
      "Validation Loss:     0.9156 Accuracy: 0.948837\n",
      "Epoch Number: 100\n",
      "Epoch 100, Batch 0: \n",
      "Validation Loss:     0.9250 Accuracy: 0.948837\n",
      "Epoch 100, Batch 1: \n",
      "Validation Loss:     0.9399 Accuracy: 0.953488\n",
      "Epoch 100, Batch 2: \n",
      "Validation Loss:     0.9275 Accuracy: 0.958140\n",
      "Epoch 100, Batch 3: \n",
      "Validation Loss:     0.9225 Accuracy: 0.958140\n",
      "Epoch 100, Batch 4: \n",
      "Validation Loss:     0.9248 Accuracy: 0.948837\n",
      "End of Epoch Losses:\n",
      "Training Loss:     0.0000 Accuracy: 1.000000\n",
      "Validation Loss:     0.9248 Accuracy: 0.948837\n",
      "Training Completed\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Removes prior weights, biases, etc.\n",
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "# Create placeholders:\n",
    "    x = tf.placeholder(tf.float32, shape = (None, 3,256,256), name = \"x\")\n",
    "    y = tf.placeholder(tf.float32, shape = (None, 2), name = \"y\")\n",
    "    keep_prob = tf.placeholder(tf.float32, name = \"keep_prob\")\n",
    "\n",
    "    init_g = tf.global_variables_initializer()\n",
    "    init_l = tf.local_variables_initializer()\n",
    "\n",
    "\n",
    "    logits = conv_net(x, keep_prob)\n",
    "\n",
    "    # Name logits Tensor, so that is can be loaded from disk after training\n",
    "    logits = tf.identity(logits, name=\"logits\")\n",
    "\n",
    "    # Loss and Optimizer, using the sigmoid function for binary classification rather than softmax\n",
    "    cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    cost = tf.reduce_mean(cross_entropy)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "\n",
    "    # Accuracy\n",
    "    correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name= \"accuracy\")\n",
    "\n",
    "    # Keep track of loss, set up patience_count for early stopping:\n",
    "    train_loss = []\n",
    "    valid_loss = []\n",
    "    patience_count = 0\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    with tf.Session() as sess:\n",
    "        # Initializing the variables\n",
    "        init_g = tf.global_variables_initializer()\n",
    "        init_l = tf.local_variables_initializer()\n",
    "        sess.run(init_g)\n",
    "        sess.run(init_l)\n",
    "        \n",
    "        # Training cycle\n",
    "        for epoch in range(epochs):\n",
    "            print(\"Epoch Number: \" + str(epoch))\n",
    "            \n",
    "            for batch in range(5):\n",
    "                for batch_images, batch_labels, batch_paths in get_mini_batches(batch_size, train_images[batch], train_labels[batch], train_paths[batch]):\n",
    "                    c = list(zip(batch_images, batch_labels))\n",
    "                    random.shuffle(c)\n",
    "                    batch_images, batch_labels = zip(*c)\n",
    "                    train_neural_network(sess, optimizer, keep_probability, batch_images, batch_labels)\n",
    "\n",
    "                print(\"Epoch \" + str(epoch) + \", Batch \" + str(batch) + \": \")   \n",
    "                print_stats(sess, valid_images, valid_labels, cost, accuracy, \"Validation\")\n",
    "            \n",
    "            # Display train and validation loss at the end of each epoch:\n",
    "            print(\"End of Epoch Losses:\")\n",
    "            train_loss.append(print_stats(sess, batch_images, batch_labels, cost, accuracy, \"Training\"))\n",
    "            valid_loss.append(print_stats(sess, valid_images, valid_labels, cost, accuracy, \"Validation\"))\n",
    "            \n",
    "            # Implement early stopping:\n",
    "            patience = 15\n",
    "            min_delta = 0.01\n",
    "            if epoch > 0 and valid_loss[epoch-1] - valid_loss[epoch] > min_delta:\n",
    "                patience_count = 0\n",
    "            else:\n",
    "                patience_count += 1\n",
    " \n",
    "            if patience_count > patience:\n",
    "                print(\"Early stopping...Saving Model...\")\n",
    "                break\n",
    "   \n",
    "                \n",
    "            \n",
    "        # Save Model\n",
    "        saver = tf.train.Saver()\n",
    "        save_path = saver.save(sess, \"./training_sess\")\n",
    "        \n",
    "print(\"Training Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By tweaking the code and adjusting the hyperparameters, I've increased the accuracy from my prior submission by 7%. Now let's check the overall fit of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nigAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14561d390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(train_loss, label='Training loss')\n",
    "plt.plot(valid_loss, label='Validation loss')\n",
    "plt.legend()\n",
    "_ = plt.ylim()\n",
    "plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the training and validation loss over epoch, we probably trained the model for too long. Ideally, we would have stopped around 42 epochs. By training for 101 epochs, the validation loss eventually runs away from the training loss, resulting in overfitting.\n",
    "\n",
    "\n",
    "### Goal 3: Evaluate the neural network and show us the results\n",
    "#### Testing the Model:\n",
    "\n",
    "We will test the model using our test_images and test_labels data. We will do this by first creating a method to display a few random predictions. Next, we'll create a method to test the model that will load the model with get_tensor_by_name and run it again our testing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "plt.clf()\n",
    "\n",
    "def display_image_predictions(imagez, labelz, predictions):\n",
    "    n_classes = 2\n",
    "    label_names = [\"Not Food\", \"Food\"]\n",
    "    label_binarizer = LabelBinarizer()\n",
    "    label_binarizer.fit(range(n_classes))\n",
    "    label_ids = label_binarizer.inverse_transform(np.array(labelz))\n",
    "\n",
    "    fig, axies = plt.subplots(nrows=4, ncols=2)\n",
    "    fig.tight_layout()\n",
    "    fig.suptitle('Softmax Predictions', fontsize=20, y=1.1)\n",
    "\n",
    "    n_predictions = 2\n",
    "    margin = 0.05\n",
    "    ind = np.arange(n_predictions)\n",
    "    width = (1. - 2. * margin) / n_predictions\n",
    "\n",
    "    for image_i, (img, label_id, pred_indicies, pred_values) in enumerate(zip(imagez, label_ids, predictions.indices, predictions.values)):\n",
    "        pred_names = [label_names[pred_i] for pred_i in pred_indicies]\n",
    "        correct_name = label_names[label_id]\n",
    "\n",
    "        RGB_img = img[:,:,::-1]    \n",
    "        axies[image_i][0].imshow(RGB_img)\n",
    "        axies[image_i][0].set_title(correct_name)\n",
    "        axies[image_i][0].set_axis_off()\n",
    "        axies[image_i][1].barh(ind + margin, pred_values[::-1], [.4,.4])\n",
    "        axies[image_i][1].set_yticks(ind + margin)\n",
    "        axies[image_i][1].set_yticklabels(pred_names[::-1])\n",
    "        axies[image_i][1].set_xticks([0, 0.5, 1.0])\n",
    "    \n",
    "    plt.show()\n",
    "    print(\"Display Image Predictions Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./training_sess\n",
      "Testing Accuracy: 0.9196428571428571\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f8bbef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWUAAAFACAYAAABk5G0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3Xd4XMW5+PHvu71Kq96LbdmWu3HBxjTbdAglhISSAiGE\nhIS0G3J/uUluIOGmkUZIJYUQOoSEaky3Me69W5abZPWuVdm+O78/zjpRhNywsdb2fJ5nn9XOnDI7\ne/Tu7Jw5Z0QphaZpmpYaTMNdAE3TNO3fdFDWNE1LITooa5qmpRAdlDVN01KIDsqapmkpRAdlTdO0\nFKKD8vsgIl8Wke0iEhQRJSJfHe4yaf8mIjUiUjMo7ZbkZ3XLB7hfJSKLP6jta6eHUyooi4hZRD4r\nIu+ISKeIREWkVUQ2i8ifReSq47CPG4BfASHgfuB7wMpk3mnxTykii5PvdeCjV0TWici3RMQ53GX8\nIAwV7DXteLMMdwGOFxExAy8DlwLdwAKgHrABE4CbgErgxWPc1YcOPCulGo9xWye7vwE1gADFwLXA\nD4CrReQcpVR0GMs22HMYX55NH+A+xgGBD3D72mnglAnKwI0YAXkTcL5Syj8wU0RcwKzjsJ9CAB2Q\nAXhYKbX4wAsR+Q6wATgT40vwb8NUrvdIHg/+wy54bPuo+iC3r50eTqXuiznJ54cHB2QApVRAKbVo\ncLqI2EXkmyKyRUQCItIjIu+KyMcGLXePiChgXvL1wJ/utyTzAM4flHdPcvny5OuHRWSUiDwrIh3J\nn/2vi8jE5HI5IvJHEWkSkZCIrBGReUOUu1BEvisiy0SkWUQiItIoIk+IyPghln8+uf8vD5F3bzLv\nL4er5ENRSjUB/0y+PHPA9muSjzQR+UXy7+iBukkuYxGRL4jIyuRnEBCRDSJyp4i85zgVw50isi1Z\nTw0i8hsRSR+qbIfqUxaRYhF5QER2Jc8TdIrIahH532T+3OTnWwaUDfp8Hx6wnSG7r0QkXUR+JCI7\nk2XtEpHXROTCIZade+C4EZGpIrJARLqT9fGOiMwZYh2viPyviGxN1l2viOwRkadFZPpQ9aGlrlOp\npdyRfB5zpCuIiA14DTgfqAJ+C7iA64CnRWSqUupbycUXJ59vwfjn/N6ATW1Mvr4bqAUeHpC3mP9U\nDqwCdiSXKwc+DCwWkbOAV4Ee4GkgE7gBWCgiY5RS+wds5zzgm8Ai4B9AHzA6WfarRORspdSmAcvf\nitGKvU9E3lVKbUjWwQXAt4DtwJcOWllHTpLPg2+qYgPeTr6n15PvcV+yDFbgJeASYCfwBEaf/Tzg\n1xi/cD45aHv3A1/G6I74IxAFrk4uawMiR1RYkRkYx0AmsATjS8UFjAfuAe7F6KL5HnDghO79Azax\n8TDb9wHLkttbk1w3G/gY8LqI3KGUenCIVWcA/w2sAP4MlAIfAd5KHpc7k9sXjGNmzoBlYxjdSfOA\nd4F1R1IXWopQSp0SD+AMjH/EBPAoRv9m2WHW+R+M4PEKYBmQnovxj6iAOYPWWWxU25DbU8Dig+SV\nJ/MV8O1Bef+bTO8E/gCYBuR9Mpn3y0Hr5ALeIfYzBSNALxwibw5G8KoGPEAeRlALABOOoq4XJ8s0\nd1B6AdCSzPvkgPQDdfkm4B5ie/ck838NmAekm4G/JPOuHvQ+FLAbyByQ7sAITAqoGbSPW5LptwxI\ns2F8MSjgpiHKVTzodc3g7R7u8wceTKY/CMiA9NEY3SlhoHxA+twBx8ktg7b1uWT67wakTUqmPTdE\neUxAxnD8P+rH+38MewGO65sxWh9NAw5qhdGCfg64cojld2EE8coh8j6TXP+hQemLObagvG9g4Enm\nlSbz+hkUaJOBKQosOop6eBGjpWkdIu+byX09jtFiVcBtR1nPi5PrPZwMqN9LBs+uZPqqgfvm30F5\nyhDbMiU/oyYGfDEOyPclP6NnBqT9Kbm9Tw+x/IGgVjMo/ZbBgQ6j5amAF47wfdcM3u6hPn+MoN8P\n9DLgy2NA/r3Jdb47RPmXDrG8NXksrB2QdiAoP/FB/3/px4l5nErdFyilnhGR5zB+tp2D0Xo+B7gG\nuEZEHsH4p1Qi4gUqgAY19Amat5PPZxznYm5USsUHpR04aVitlOodmKGUiotIC8bP0f8gIlcAn8f4\nqZvNe7ujsnnvaIOfYNTPTcnXTyql/nzU78Jw84C/+zG+5P4B/EK9d+RFCNg8xDbGYHQd7AK+Y/wa\nf48gxsiGA6Yln98ZYtmlwOD6PZjZyeeFR7j80RqL0RWyTCnVOUT+28B3GPoYWzs4QSkVTR4LGQOS\nt2N0odwoImXACxh1sFYpdURdOFpqOaWCMhgHLkYL8HX411C5jwAPAZ/CaDU/Dxw4IXSwIVIH0n3H\nuYhDnYSMJYPRwUYHxDBaSf8iIl/B6J/sAt4A9mN0QyiML6EpgH2IfSkR+SdwcTLp/sHLHIV5asDo\ni8NoVUoNdfPurOTzaIw++YPxDPj7wGfXMnihZF22H2GZDny2DUe4/NE6lmOs+yDrxDB+PQH/+tKe\nD3wX43zCT5JZvSLyN+B/lFJ9R1VqbVidSqMvhqSUiiulngF+mUyan3w+EADzD7JqwaDlUoaIWDC6\nDZox+oKvV0p9Qyl1t1LqHoYIVgPWHQ38DCOYJ4A/i4jjgy/1e078HXCgfp9TSskhHiOGWCdv8MaS\ndZN9hGU6EPiKjnD5o3VCjjGlVJdS6mtKqRKML7fbME5c3wn8/li2rZ14p3xQHuBAt4AAJLsJ9gBF\nyUA12IFhaOuPYh8JBrRiPkDZGK2r5coYhvYvIuLh3z/vGZRnxxjV4QauB36E0Sd5LK3lY1WFERxn\nJ0dhHIkDn8n5Q+Sdw5F/BiuTz5cd4fLxo9g2GCNJAsCU5CiMwd7PMXZISqndSqm/YNRNH8aIFO0k\ncsoEZRG5UUQuOsiY1nzgs8mXSwZkPYQRpH+a7OY4sHw2xoiIA8scqQ6g5KgK/v60YvyzT08GYeBf\nQ8t+xcFbij/D6L+8Tyn1BkZ3wTLgcyLy0Q+2yENTSsUwRl0UAA/IEJdoi0jBoLHXDyefvy0imQOW\nc2B80RyplzBO3l0lIjcOsd/B/fgdQM5QZRxKsk/3ccCLcVJv4LZHYQzpi2KMFnpfRGSEiIwcIisD\no/sq+H63rQ2PU6lPeRbwFaBZRJaSHAMLjACuAJwYJ0GeHbDOzzBaSVcDm0TkFYwTMx/FGHJ2n1Jq\n6VGU4S3gBhF5CaP1EwWWKKWWHHq1o6OUSojIAxgjKbaIyAsYZ/rnYZw0W8S/W2EAiMiHMX7OrsI4\nuXSgP/JGjBNFfxaRdUqpvcezrEfoXow+8M8DV4rI2xj9vLkYP8fPBr6NcVILpdQyEfk1xrjqrSLy\nLP8ep9zFEV5KrZSKJL+MXgeeEJHPYbSeHRgnFi/gP/9H3gJmAq+KyBKM4WyblFIvHWI33wTOBe4U\nkZkYn82Bccpe4E6l1L5DrH84U4B/isgajLHvjUAORl1Y+Xcfs3ayGO7hH8frgdFC/SLGibydGBcn\nRDD+QV8BPsGA8b8D1nNgXDyxFaNV0Ytx9vrGg+xnMQcfEpeLceFDC8ZPXQXck8wrT75++CDrHmo4\nXQ3vHeJlAf4LI1AFMfqXH8W4sOXh5PbKk8uWYoyB7mbAmNgB27o6ufxqwHYEdb2YIcYpH2L595R/\niGUEY0z2W8myRjAC89Lk51MyxPJ3YgSiMEYw+i3GybWh6usWhhj7O6B+fofxRR7BaBGvAr41aDk3\nRh9tPcYJt//4PA/2GWJ0Nf0EY4RJOPk5vAFcPMSycwceN4erS4xROT/E+MXTnNx+PcaIksuG+/9S\nP47+IckPVtM0TUsBp0yfsqZp2qlAB2VN07QUooOypmlaCtFBWdM0LYXooKxpmpZCdFDWNE1LIToo\na5qmpRAdlDVN01KIDsqapmkpRAdlTdO0FKKDsqZpWgrRQVnTNC2F6KB8lETkYRH5v+Euh6Zpp6YT\nFpRFpEZEWkXEPSDtNhFZfITrLxaR2w6RXy4iSkT6Bjw2HYeia5qmnTAnuqVsxrgR/QfJp5TyJB9T\nPuB9aZqmHVcnOij/FLjrIPOVISJzRGSNiPiTz3OS6T/AmL3hN8kW8G+OZqciYhKR74hIbbK1/oiI\npA/Iv0pEtolId7JFPm5A3hkisl5EekXkaYyb4muapn0gTnRQXosxa8VdgzOSc60tAB7AmHb+F8AC\nEclSSn0beBdj6hyPUurOo9zvLcnHPGAkxnT1v0nudwzwJPBVjGl0XgFeEhGbiNiA5zFm9MgE/g58\n5Cj3rWmadsSG40Tfd4EviUjOoPQrgF1KqUeVUjGl1JMYMx1feZTbb0+2eLtF5EDw/zjwC6XUXqVU\nH/A/GHPpWTBmdV6glHpDKRXFmLfPCcwBZmPMc3a/UiqqlHoWWPM+3rOmadoROeETpyqltorIyxgT\nSu4YkFUI1A5avBYoOspdZCtjhuSBBm+7FuO95w3OU8akpHXJ/caBBvWfc2YNLqOmadpxM1xD4u4G\nPst/BtxGjEk/ByrFmDwTjMkk36/B2y7FmPiyZXCeiAjGJKwNGJOuFiXTBq6raZr2gRiWoKyU2g08\nDXx5QPIrwBgRuUlELCJyPTAeeDmZ34LRH/x+PAl8TURGiIgHY/bfp5Mt6meAK0TkAhGxAl/HmBF4\nObACI3h/WUSsInItcOb7LIOmadphDefFI9/HmLIdAKVUB/AhjKDYAfw38CGlVHtykV8B14lIl4g8\ncJT7egjjZN0SjGnkQ8CXkvvdCXwC+DXQjtGHfaVSKqKUigDXYpwk7MTof/7nUb9TTdO0IyT/2V2q\naZqmDSd9mbWmaVoK0UFZ0zQtheigrGmalkJ0UNY0TUshJ/zikaHcdct81dXVT1qal05/HxmZ6YiY\niScSdHT1kpHuRcSMyWKBRIxgOIrL5cJqNWG3WhhZUoC/r59uf09yGyG6enpxO+x405y4HU5CwT7y\n83LYtbuWUKCPQCiC3W4nEAxTXpyFx+NBLA5KC7MQUcTCET565y/k8KXXUkF2drYqLy8f7mJo2kGt\nW7euXSk1+Erm90iJoFxT10F6mosMnwen005/MEI4ESEUSeB0OInFYphMMSzWBOGEwmUX0h0Qicfo\n7wuwpzZKZoaXtvZOmprbsVgsuBxOEpEw3d1R9nY1YLPZ6Pb3EQwE6A1EsUiCYCCM1+ugvTeK3WWi\nv7sXr8dBJBQgKzNjuKtFOwrl5eWsXbt2uIuhaQclIkd0NXBKBGWlFGkeF5DA7baSmeFlf1MHgWgf\nael2uvuCuBw2zCK4bUI8HicUjWExxTBJgrr6Frq6ewmHozgcNhIkwCT094cxW8yMKMmns6cfX3oa\nCTHRH/KTnemhraOHvr44CUsYk81FrtuDw+UmMzOT/DwdlE8mWxr8lH9zwXAXQzuN1fz4iuOynZQI\nykiC1q4+2v0BvG47NpsVpRQ2qxm7zYzHYSUQieFw2Ej3eunt7SXT58JhsbKlugan00lndx8iZoLR\nBDYx09HZSn6OD0xmotE4TpuJrMx0vB47ZhXD5/NittlI96aRkeGjoKAAEPw9fnq6O6kYoa+mfj9E\nJA5sGZB0jVKq5hi3uRi4Symlm8LaKS8lgnJmRhqRaIzyklw6u3tJ87oJhiJYLWYsVjsZGU4s/f1k\nZaaTiIQpKcylraOLmu5OIlFFPBLCZLHitNuIxxUmi5l0l4NoQuG0QJrbjoiTxqZmnA472Rke/D1B\nbGawmRJkZabh8/kwSZyyknwWvbOM1tbu4a6Wk1VQKTV1uAuhaSerlBh94Xa7yfb5aG3vwu1209sX\nAMCkhKL8TNwOC7lZWYRDUZxuL3a7leKiAmZMGU3lqBLyc9IoyMkkOycTu9tNMBqnpz9IIBAhNzcX\nd5oPsVjxuLz4fD56+kLUNrbh9drxuJ30dHZQW7MXEgk62tuZPWMSjXX7hrlWTh0i4hCRv4rIFhHZ\nICLzDpPuFJGnRGSHiDyHcStVTTstpERLOSfDQ0LFSVMumlq78KWn0dPTg93hQFDYbBY6u/toae3G\n43bS1NJFRpqXiBlisQS9fWEyMm10d/UQjSewWgST2YLL5SA7Kw2z1URvby89/SHcXif5OdkEQlHa\n2nqxO5z4MjOwOTz4/X7Ki/PZvXsvHe1dw10tJyuniGxM/r1PKfVh4IuAUkpNEpFK4PXk5AIHS78D\nCCilxonIZGD9cLwRTRsOKRGUW1s7CYYixGIx/IEQ8XicrKxMPG4n6zbtpHJUCf39/aSluYhFQuRm\n+7DbLNjtNmobW5k0tgylEpikj56+EN39/UTjikCnH39vD/6+KP2hIEXZmVhMJqKAy2Glv7+frKwc\nPJ40zFYrLpuVxsZm0tPTKS7OHu5qOVkN1X1xDsYNn1BKVSXPQo85RPp5GDPQoJTaLCKbh9qRiNwO\n3A5gTjvsSCNNOymkRFAOxeLkZzvp9IcIRqMolUDFQnR1hfC4HbR0dJOV7mFffTset52uri7MZjN2\nm4VMnxOH00ooHKMoL42Glk4sCCabhYSyoZSQ5XNRZPNRV1dPUzhMJBpHSOC0OwlFIvT09RGJxHA6\nnUTDQTwuJwmTdbirRTsMpdQfgT8C2AtG6ztraaeElAjKKhanobmLrr4Q2RlpdPf1EQyGMJuthCMR\nEgocNisWq5V9ta1EE3GsJjN2m1BWmEeoP0B9azeRcBSXNYHT5cGX7sVks9Pb18uIkiJq6hoJR2IE\ngmFisRjtnX2kpXnwb6xm9vQJpPsy6evrp66+kyhgOaZ76muDvIsxJdfbye6JUmDnIdKXADcl0ycC\nk4el1Jo2DFIiKPv7eslMcxKORuj0B3G7HYTDURKJMImEwmIWrFYzsXiceDxGJJLA4oB43ERfoB+7\nzUwkEsLltIHJQVtXD919QfKzM+ju7iE/JweHzYo3N4PmVmhvb6cwL53uoKI7ZOONVXuxWhvwpGcy\nYco8Jk47k52L/jjc1XIq+R3wexHZgjFpwC1KqbCIHCz998BfRWQHxpRh64at5Jp2gqVEUI4nhGAo\ngdfpJi6KDn8fdrOVcDSMmIU0q5P+/n5sdjNOpw1UnC5/P1kZLvy9IVpauzFZzNgsJmxWG2kuOzEF\nja0d+LxumptbCUbj5Pg8BPp7Ua4COkJRlCmBYJwsDIb7sdg9NDU34tlTyxmXv2fCbe0IKKU8Q6SF\ngE8fRXoQuOEDKaCmpbiUCMrhcIJ4IoLdZiEeCQMQisUwIbiddvz9IdKcVsxiIhSMEI8n8DjNRMMR\nWnpCZGV4CYTCIGYQE53+ECJCWUkWwUCEWCKGzSTUd0QJmDIJBsOICIFgFIjiy8zEYbIyatQ4Wrr7\nEFOCjdurOaMyb3grRjtik4rSWXucrqjStOGUEkFZmQRIkEgkcLtsWGNm+gIhTCYT4VAcq9WKyWxG\nxEx2uoNYXBARIvEEJnOYdn+A4vwMIrEEvT1+evoDOJ1OqvY0Eo/HmTx5Ms2dAULhflxOJ9luN8Fg\nmP5gGJ/Ph2DF5U6ns6efsvJRBIMJcoqzhrtaNE07DaVEUI6Gwzi8blQCHA4XsUAUq9VKXCWwO2wk\nEgliMQiGwvQHgoweVUp3VzcdPX2YlImMNBdKxen29xGPK9xOG7d84iN0tLXR2hugvrkHk9lMdlYG\n0WgUq8VCINHP6LFjEayEo3ECoTgOseNOz6Sjo4fS0e7DF1zTNO04S4mg7HY78bjtoBLGZdMKrDYz\n5riZeMKEw24l0B8CARE7za1ddPWEEAVms4X2rl7sAScWE5gsFiZOmIC/u4tNe1tJJBK0traSk5dL\nJBrFbrPS09tHZm4B3rQcRo6soDsQoWL0eDZvq2bf3v2MrpxMS2s7UDbcVaNp2mkmJYJycV4G/kCM\nC+dOYcvWXdS29GIxmXE4LSgUVqsVp82Ky2Elw+ugsbWLNLcNpRIEQwlsZitWsxCIRPHYbZSVFLJm\nRz0Wi4V4LERZeSEoCyaXC4/XR2aeBavVSndvhIbmDny+TMRsZ/rUKezYW4syCRaLHqesadqJlxJB\n2d8fJMvnYvnq7ViJkZ3mwG630xcME4/FSfO6MEmcSDBCbXMHGR4H7d1hrBYrCcKYLSZCQeNCk+kz\nZ1Pf7ifd5yXQG0BhxWKxYLM5aKhvIhgRikpKsDq8pGV7icXjuDMyaW5ppbGhjRlnzSYUSmC1p0TV\naJp2mkmJyON2OekNxAiGIridNoKhfqKxGFaLhVgiRla6g2AoTEmeh0A4QUNzJwX5GXR1dpPmttDf\nH+Cj119NQ2cAi9NDT0cjHo+DjEw3fb0BamvrcNhdBMNxbM4YZ845i0BAUVhcxt6aOgoLR/Lscy+S\nX1xGa3sXZrsLh6TEvZo0TTvNpETkSfc4cNutpHsd+NIcjC7Jxe6wYrGYSCTi9PYFiUYjmEwmcjKc\nFOekk4hEyfQ5GTv9bPb32mjvjVJfX09eZjqjRpSQ4fNgsZiZf9HFqKiJiy++iJs//WkuufxD3H3P\nL+jxB2lt7yIt3Ud2fi79YYUoExaLhZamVhqbm4a7WjRNOw2lREvZ47SS5fMQDAbJzfYSCUbpDoYx\ni5Dm9RKLhuj290EsilKKvNxMorEwxeNm43K5+Pi1F7Bvfx2zZ81BLMK27VvIzc1l1coNOJ12ykYV\nM7JiFC++vASHw8bMGVM486yz6AuG+MUv/8Tsc9v59ne+wLIV1ZQUFYKpHl+mHhKnadqJlxJBOS8n\nHUwmookEo0aUEe7vIy3DSyQSpa2nH7vJRGFOGi6Pix27Gqhv7uXMeZezdVsVNocNv9/PhRecj8Xs\nJC8vm872LspHFFJSXMqaDdv42Mc+is3hRWHGl5GDv7+d5StXsmbter5z9128/NJrPPHYS7S09dBT\nOZai4hL21+6FGfrOY5qmnVgp0X3h9XrxuFxMrRxJMBImMyeH/kAYj8dNVroXl9uFWGxYLSbyR0+h\ndMJ0QuE4ZouNkqJi5s+/AH9PkP7+Xr5/70+YPnMqS5du4Nl/vMoPfvADIjF46aW3GDl6JGabBYfX\nSeW48fh8GSxcuJAuf4iyslF8+MNXk5GdSXtbGyNsO4e7WjRNOw2lRFA2maxUlBdjtZnxeFxEVZyx\nYyrIycmlvCiHNK+bnGwfmeXTKSkqpqS4CLMpRprXyqzZM1iw4CVGjcqnuqoOu81NLBYnFI3w01/e\nyydvvpm8/HwKirMpLi7jQ1ddSsXIyZSUFNLdE8NkMjPn3FkkJEFV1U6I9ECohUBj1XBXi6Zpp6GU\n6L5IS3Pz4Bt7eH1XJ8TixONxlFIkYjHi8QSJWJSHvvFRgtEge/fuYfTokTQ1NzFr1lkEA1Fu/tSN\nTJgwk7cXbaG7J8DC1xcyb/58MrPzyM2r4LbP/RfjKsczbkwfP7rvz/ziVz9g/YYa4vEokagJt8tD\n1bYaikoLINbDW6+9wAXj9DhlTdNOPFFq+O8bXHrhVUol4sQjEUxi3AcjFo4gIphNJu6/4xKyMny0\nd/fhcHgIx3pZs3ojNfv28+WvfJGOjn62bd3EI4//kx/83w9paqvFanbx578+yvMvvoTd6cXr8VLX\n2oHNZuat11fh9XkxWd2MGV+J39+PiJ2O1lY6GrfTsP4ZzCYT/+/Hj8hw1412ZGbMmKHWrtWTXWup\nS0TWKaVmHG65lOi+EBLEIkFMKKxWwW6xEk9EyTAl+P1Xr8bhcLK/vpH29ibGVpYxcfxE8nOz+dzn\nPslTjz9Lzb5qPnXzTWzYspTnn3+OuedfyDPPvsx9P/k5fZEodXUNdPV309rUic+XwbyLzmHT5v24\nvT66+/ppamyjpnYf+3ZvpX7/biaMLae8JHe4q0XTtNNQagTleAybxYrdZibd60UlYvz+S9fyozuv\nYc+ueqLhEG+9vZx43I4pbuIvD/6Fyy+/ktWr1zJl2ngi8QC33/51Xnl5ARPOmMHit1cSCkbZsase\nk7IzYeJ4qqv34vFaCYUSNLf285nP30gslmDZO0upHDsKrw1M0R7K7A3E4hCPm4e7WjRNOw2lRFBW\nyphdJBaLEegP8KNbLyERD1OYl8Pe/fuoGDeeL37+FjauXU1mlhdvWiH3/eheVixZx86djdx6663k\n5WVx5pnns3PLPm7+zK38/k+/o7p6Fy+/uJAXXlzEvd/7DXV1fbR39zJuTAHZXhPPPvssFrGz+M03\n6WyrJ9TfSaO/j/7+ALFYdLir5YQQESUiPx/w+i4Ruecw61wjIuMPknePiDSIyMbk48fHoYxzReTl\nY92Opp0MUuJEn9ksxKJRErE4933hMnIy0rCYFOFYgts+fQNOm43G7i76++P0+Hu5+JKpbKvyMKZy\nPFs27WXdut3ceP1tfOFzX+ETt3yapctX8sTjf+eHP7mX6r0tlBXn8dijv8Xr8/CLBx7hji9+ihee\nf5u7v/3/ePjxp/jwdVeydu0q/H4/9z+ymFgsjsudzqf+a7hr5oQIA9eKyI+UUu1HuM41wMvA9oPk\n/1Ip9bPjUjpNO82kREvZghAJhXnwro+T4XVQVb2T2rpGgsEALc2ttHa0kZWTzXe/+xX21u6luGg0\nb7y8knEVZ3DTTTfwzjvv0NDcwDPPPsPGjdW0NnfwiZs/QWZWHm1NTfzwx7+ltSNIa2uEL9/5Kfxt\nPYysqGDD1k2cc9aZ/PJXv6S5bhc1dfuJRcNYEnFCwZ7hrpYTJYYxI/TXBmeISLmIvC0im0XkLREp\nFZE5wFXAT5Mt4VFHshMRuUBENojIFhF5SETsh0m/VESqRGQ9cO1xe7ealuJSIigHAn3cfeMFxKP9\nNDY3kZWRQX1DC6WlucyZPQsVjPPPZ9/Am2GnpCCPPXu38eOf/ZBgMMZ3v/0zPnbTTVxxzVW8s2Qt\nfYFeps6YzPz559PT08vLz7+ImBL0dLeAhHhpwTI2b91HfWMbM86YgsubxszJo9i+bSsLFi8hHo0S\ni4SwWlKiak6U3wIfF5H0Qem/Bv6mlJoMPA48oJRaDrwIfEMpNVUptWeI7X1tQPfFJSLiAB4GrldK\nTcL4hXbHYdL/BFwJTAfyhyq0iNwuImtFZG1bW9ux1YCmpYiUiDwPfOljuB0WGurqAdi9s5r5583h\ny//1M75A2H4wAAAgAElEQVR/9y+wOWJ86eufYO/2/fz2oQU88KsnaW5uIj3TxS9/9WP6enq5846v\nkZ6exn33fYtXF7zJs8+/yZVX3cL37r2br3z1DsZUlrFk0UocNicTJpYTjyheev4tFjz7NCXlZZit\nikgkgjmRQESIx+PDXCsnjlKqB3gE+PKgrLOAJ5J/Pwqcc4Sb/GUyYE9VSr0GjAX2KaWqk/l/A847\nRHplMn2XMsZsPnaQcv9RKTVDKTUjJ0dfEq+dGlIiKOdkphMI9BCLK8pLy+jvD/HYoy9w/0+/QnVt\nI0899Sb3fPs3lI8q4Wc/+RKtTX4cdi+xCGzYtAW3N4PHHv8b+2rqeOih5/n0bZ9l5Khcfvnze9lZ\n004gGGbligbGVI4lHAjS3WNiwuTxjK/M441XXmbRoqW0NjdhEggHQ8aJx9Pv1p33A58B9DxYmjaM\nUiLyNDe3kpWdzZ7dtbz80pskxMqoMWk0N3Zw3w++yD3/ezvfvOuzRGJxnnn8DS68ZC6PPvIUvhwv\nD/72z1RWVPDWokVMmnIGW7fWEAr1UJSfR15RDo8/+hTu9BxGlWUxfkIpV18zh57uJuxmRVdXN7//\nw8/ZsG4NF194NrFQCLMJEtEIifjpMfriAKVUJ/AMRmA+YDlwQ/LvjwPvJv/uBbxHsfmdQLmIVCRf\nfxJ45xDpVcn0A/3VNx7FvjTtpJYSQXnM6HJaW9uYOmUC554/k3nzz6J2bwsTxpSyfut+MDtobGkm\nMzOT+tpWvvmtO/jCV7/CprXbuPsH/8tXv3YPe3a1UlZWwI9+9m0e+M2j1OxrIjcnm9//4f/IS7NQ\nVpHDqhWb2bunDYdN+PtTz7Dw1Veo3b+HCy+exx1f+x7xaAxJKFQigc+cElVzov0cyB7w+kvAp0Vk\nM0bA/Eoy/SngG8kTdIc90aeUCgGfBv4uIluABPCHw6TfDixInuhrPT5vT9NSX0oMiVu2fB1jK8ro\n9ofYv7uOMeNGkpldwupNm9i0dhvlpRmYsREOx+js7aatrR2vO42XF6zm+uuLGT16PHPnzeatRcuZ\nOm00VruNLVubSMsoZeOGDXzkugv53YOvsW39DvJK7HR3BrBZIvz6/u/y5z8/ysrly7BarKAUMZXA\nYrEPd5WcMEopz4C/WwDXgNe1wPwh1lkGDDlOWSl1z0HS3wLOOIr0VzH6ljXttJISQbmzo4nXdu9h\nypQJTJhWwcvPLsFks9Hamo4rPYvCgjK++MWfcOnFs/j2PXfy5mtb2bFjJ9+65/MsWLCRCy8+n9r9\n+5g8ZQJvvLaWu75+J7/93WPYHXEKi0bw0/ue5MtfuZ6ds6YSDDcQV14y3DFWr9iGw2wnJ68AUMRi\nMeKxGEV5uajT5zyfpmkpJCVuSKRpx0pEejH6qLX3Lxs40guItPc6XP2VKaUOO0woJVrKmnYc7DyS\nO3BpBycia3Udvn/Hq/5Oy7NZmqZpqUoHZU3TtBSig7J2qvjjcBfgFKDr8Ngcl/rTJ/o0TdNSiG4p\na5qmpRAdlLWTSvKWnjtFZLeIfHOIfBGRB5L5m0Vk2nCUM1UdQf3NFRH/gLv8fXc4ypmqkreXbRWR\nrQfJP+bjTwdl7aQhImaM24xehnFF4Y1DzIByGTA6+bgd+P0JLWQKO8L6A3h3wF3+vn9CC5n6HgYu\nPUT+MR9/OihrJ5Mzgd1Kqb1KqQjGPTiuHrTM1cAjyrAS8IlIwYkuaIo6kvrTDkEptQToPMQix3z8\n6aCsnUyKgLoBr+uTaUe7zOnqSOtmTvKn90IRmXBiinbKOObjT1/Rp2naQOuBUqVUn4hcDjyP8VNc\nO0F0S1k7mTQAJQNeFyfTjnaZ09Vh60Yp1aOU6kv+/QpgFZGBt3PVDu2Yjz8dlLWTyRpgtIiMEBEb\nxg34Xxy0zIvAp5JnwWcDfqVU04kuaIo6bP2JSL6ISPLvMzFiRMcJL+nJ65iPP919oZ00lFIxEbkT\neA0wAw8ppbaJyOeT+X8AXgEuB3YDAYyb6Gsccf1dhzF5bQwIAjcofYXZv4jIk8BcIFtE6oG7ASsc\nv+NPX9GnaZqWQk7r7gsRuUVElg53OTRN0w5I6aAsIjUiEhSRvgGPwuEul6Zp2gflZOhTvlIp9eZw\nF0LTNO1ESOmW8sGIyFUisk1EukVksYiMG5A3LpnWnVzmqgF5WSLyooj0iMhq4LAzMWuapp1IJ11Q\nFpExwJPAV4EcjLOdL4mITUSswEvA60Au8CXgcREZm1z9t0AIKABuTT40TdNSRkqPvhCRGozJCGPJ\npMXAOmCSUupjyWVMGJc1fhyIA38HCpVSiWT+kxgTat6LEZAnKaWqknk/BM5TSp1zgt6SpmnaIZ0M\nLeVrlFK+5OMaoBCoPZCZDL51GNeXFwJ1BwJyUm0yLwejD71uUJ6maVrKOBmC8mCNQNmBF8mrj0ow\nLmVsBEqSrecDSpN5bRgt7pJBeZqmaSnjZAzKzwBXiMgFyT7krwNhYDmwCuMqmv8WEauIzAWuBJ5S\nSsWBfwL3iIgreR/Zm4flHWiaph3ESReUlVI7gU8AvwbaMYLulUqpSPIesVdi3Gi6Hfgd8KkDfcjA\nnYAHaMa4WfVfT2zpNU3TDi2lT/Rpmqadbk66lrKmadqpTAdlTdO0FKKDsqZpWgrRQVnTNC2F6KCs\naZqWQlLiLnG/+d2P1czi82jr2UcOAYLxVt5YtpsxY6ZSXGmhZW0VnkwPkXgha3ZtoLdxD9EsNz5/\nkMzcPPa37SentIRx51xGuHkjrfUWJk3LJdztYcueINdecxHrVr7AxGmVtG3aTLPTxJRx5xPo7KYP\nwe11kS4+9rXvoru3naLCWfR1+7nquktluOtGOzLZ2dmqvLx8uIuhaQe1bt26dqVUzuGWS4khcb+/\n+39VdctuphfZ6fPlsru6mqmjKmlpqqKgcCpbQz2o/XtxZHhIi2Vjd+wl1zGZusY6igsyCfkDRFw2\nOhq7aGvrYNoll1KiTMR809i0dxf27G4i7f109fcydmQFGflucLpIC3SSnjmBgpw+mtt6iDpHU5Dl\npm77flpNCS69aK4OyicJe8FoVXDz/cNdDO00VvPjKw6ZLyLrlFIzDredlGgpO0YrPj55Nkve2cje\nzj2M8aZRvXk3YVMfIWnC2t+NVXk5IxKg3RdGxQppCfSQVTSJ+s5a3IWTcHVuIstlZeLHrmTXzl7s\no3JQHWtI9LThSnczdca5FHszUc4oW1a0EWhfQ29agogpnY62OJl5leQ7FMve+SeZORMJ1m7BmIpL\n0zTtxEmJoLxx6WYsxQW09ndRkegn0NVH0QXXURLuprV9Hfi9LGvcTv64Sva1JSjPBFOgETVtFJ7q\n0WQ67ETzSmi0NWKviRGIhehv2UZHVzulHg9mp4v9u9bwz52tXHjBZHwV+UjJdJweCxlZZvbXNhOo\nWURrYSFT54yjpsZKb5FuJL8fIhIHtgxIukYpVXOM21wM3KWUWnss29G0k0FKBOVJ7gmUFpUQi25m\n7Ng8epsdPPPWKyQmjsbvngDxWjIzp9MZNzOqchRVe1YxyTuZjC4ndZFdsLeQpp563OKmzbWDwkon\nzSt7qZxaQI3fi7uqli5iXFicR92+JeRm5WIPlRHKdVDbncYUWwU7Ik6K0svZtmQHU6eXksvI4a6W\nk1VQKTV1uAuhaSerlBh9kZFbSiwQZPnGDTRE0mno6WLOzCnEW/fiSSjSK4sYPcWJTyIE/XXMGDUJ\nU2kbjbUbGFeWRqt5JzM/eRZSYsY7ZjTRPgu+mV7asopp2dVK/qwKzigpIJJZytSysVRt38SSFS/g\nDObQtOEdqlpWklXUxPqNm5n9obks3b2b5s7y4a6WU4aIOETkryKyRUQ2iMi8w6Q7ReQpEdkhIs8B\nzmF9A5p2AqVES9lbYuGfzz/DxJGjsOVWENuwCxXtwFIyjlg4TnN1jJHTPcjIXGo2LmXk3I+wU8zk\n+9pZUrULTyDCjmVb8G/fR5OtDVt/CLO1gxGZQQoKqylwFrLXlEW/fzcbNrVyxvxL6NvXi9/zLgU5\nFZSOGoc1asbUs5Td1VXkKJhV6R7uajlZOUVkY/LvfUqpDwNfBJRSapKIVAKvJ2eQOVj6HUBAKTVO\nRCYD64fakYjcDtwOYE477EltTTsppERLee1zC7j4yosIhmpY/fpTIEH8Pfup3bqUQH0V5om9WCVB\n/YolXHT5+Wzct5rC3hl4Jp9NUdBMX6eD3Rv3EIhYmTXeQcHoPMrKRzPyrAnYvXnsre4hEQ4QrLMx\nd/ZZxDZ34bH3sPa5TZxz3TS66/awuXM1DTX1dG2pYtyMCrZurzp8wbWhBJVSU5OPDyfTzgEeA0je\nsa8WGHOI9PMGpG8GNg+1I6XUH5VSM5RSM8yu9A/wLWnaiZMSQbk+s5WN1ZsIOsZjDexC3DbizXYs\nxcW0t9joaOwgPztKXqWP2vU9TCybTrOqxxUwkT//w+D08Mmv38s5t13P/h4h3+EhM89F254qGv3Z\nrFz5Gv5gK7WNa1C2DubPLaShtZsbrr2O159+jUXrl7P+zTcp9Zho7trJhncW09G8brirRdO001BK\ndF9k9Rdgj9io3byVOfNn4546m/iofhIbl/Px//kurf4gmQ4/7tJ0aqteY/PqdeSPMmMKX8Cu9rWM\nPGMie1uaybGMZNrsC1jw+jomBLKJqt14wu2Y80czceRoOncEWLF8I7vVOmxSwqKqhbgcJeSVhGmv\nTsOTlU5p/kji3UEyxviGu1pOJe9izKH4drJ7ohRj3sSDpS8BbkqmTwQmD0upNW0YpERL+Ywbrsdt\nL2fW9bfS6rYwqWAqZ009m5I557FjYw07Ol9l0/YNLFr1CCW5MG3qJNKyCvC7NzO6q5eeRBWqu47l\nix8m1+PhgjPnEJkgmNJMnF0xFWtfmLg3Qf+oCC57Dk3hdCafN5OPnv8RRrsLuGLOZZSMKGdraxOj\n5ufREelFMnKHu1pOJb8DTCKyBXgauEUpFT5E+u8Bj4jsAL6PMVmupp0WUuKKvr8/9YaaVTqSf6x6\nkRJ7FuYsO5ZKH9FVHUQ9fmLRAmbPrmRDVz22LTtZ21PLeaWjaQ+3k+m0EfKHqNsfwuRqo722jQIx\nY/WV4LI7sI1zs/KNN7h23kfY11mL01ZGJNZEZ6MfM1F8BSPZ17aTzFonhRdmc/bZ51Ozu5ltb67l\n+h/+Qg9WPknMmDFDrV2rhzFrqetIr+hLiZYyqoUNbbsprywhMdlOwmamKGwjnJbN5LKRnJFrYX9j\nA+YOO7ubWyl2j6JuVycxuxmzL5/49k00NG4k3NlOxYhphLIz2NezCk/ZGKx9fjLiuSSsbpprqnFF\n/ORnF3H+nLlccs25ROt3ccmZl1J+VgkJf5yWBj/O/CzOvf2q4a4VTdNOQykRlGssNrqruqnduJe2\nFW24sjJZt6EJX6mVBnuIqr17eOvh+2lf9iIj0nvZseZROhOt9O3povGVpdRLmCuumEZB1kQau9fg\njgSYf84XKLSGSNhtjJsxFXGFyMiYSP6lkzl7dB4d9XvYsqyFs667nGi2GXdRJd0hG5uX1ZElito3\nhhyFpWma9oFKiRN9+bF6LFeUcWbDlWTmpaEaq9iX5qdcRtDY24arIsZM2wV4ijyYvQ5m2Gbjm1bA\nWKuNtu2v8MJj1XjSOgnST5pkEIp5WL3pDaZnOvn5gy/xyYsvpCUSo3LcCFa8s4GtLYqKygwaN9Zz\nbnAcT730B1wdsLe5m4/efB2rNldRUmoe7mrRNO00lBIt5ZHjp9CydCt9NFP9jwfoqPBRFC0n4XKy\n9k9LqN1vxpuXicc6GXtgDFPnjmL86IlsadhBV7+ZW7//OVS6mymTL6Uwx063RBk/awKl517Lff/9\nDXb1NuHf4qNpp4f43i4uPHMcq1aspPzMmSxa8Sqfu/zjTPnIpTgyfDS3hmne08Gry1YNd7VomnYa\nSomWcpYzn5EZk9jXUMX4C2+lKM+DP0fYsHgFkyZlUb31TdrDl9PkexOnNUpCprPwoT9BtI8Sl52V\nzulUbV/H24+/Rl66ifHzK9n8xFrCl/eyfeVyLpx/MQ8++ihrV1iZftEFvLp/J9PPnULFiBwWrAzx\nk/u/jjP9XMaML8bhcPBG1V+5+YZbh7taNE07DaVEUN68ZjWb31yI3S7M+NDVNOytJbPCTSyaw1sL\nl+Pt89O86BEmTzmHIC7+vu8ZvnTFufTFTaxuWs5I1w4mf/RrxD+0jT5bJgsffIyJF1QSbYOJYwso\nG1XCF669g4ljJ9LXtxfb+EJeefHvhJq9jJ05m5fWL2Jen5++drjoHDOdDZfx9K+fZtbldw131Wia\ndppJiaA89bKL6U1PpyyzgvjOLSRCmXSsWIOnaycOsZE19TrSVR272zqYOTGXa/PKeODBX5FfUcCs\n8suRsA+zt4XtK7ZS6RvPrp4gFyg7RWV5bGtx8MTvnqGtdi+Rz3+GuCVK/tsBivILaO/ZSGXhfK6c\nUEkidwquYJx332lk3NlXE8rSNzrTNO3ES4mg/PBfn+Dqiy6mZftebGmF9NubcYwZQ2ffGCaf7abS\nbqGlYwm+jDFsrF7J1LLRXHDbLaxcuIItDTvx97s4N5pDxJPOS7trmHmmhy37eklz1JOXkUfmh2by\n9PN1lI8YRd+eKtasXkak1E52cTGrn1hLKHM2+RW55IUtFJw9h/6qTqb5QsNdLZqmnYZS4kTfnImV\nKH+AssnjaGlqJ7doFtnePCaOy2BGvo1W6SLHVMmmRY8yryKflubtFBaNItFTRRg/mZYIL/9jA+fP\nmMeOzUvIaxnJmUUVyJQRLFz0JmWOPK667Er2rVnH67u3UBds5vzxkzE1tGDJM1E5+1yi0VKyZk+l\nedFmAl7B5NV3idM07cRLiaA8cuYExBpnXW8T5rPyMat+Glu207O/muXVq8jq3cDenu1cefMXSWTl\nMqZ0Asv+/Agul4t2f4iinAm0t7fxxKpV/PFPv2WXaiPoDdBX1U1FZRlZY0awZ08DMWce7oiL+dNm\nEbbESDvjUmy5RZSMCjN+hAkCGZRefh5Oaw6FUw974Y2madpxlxLdF9uXtjO6IsZMyaejoZayC0ew\n6MmldNnN+PudrLc00tndTU9JMZOKxrF+Wx1jJsxi7QYv5aNtrN/yEplFTnIcsOaNDXz5hitYtWcr\n3Tv6uebmq1jw1gpGlRYzddJoqiO7qHV0YW0EdyJBPFTHgp8v5fz5l+Ae2USoJYt4ww58oz463NWi\nadppKCWC8hkT83G6wRQwYcoow9qegdVXQbx/C+dNnUhVlweV3cKI/FI2Vi0h6vUSz80k55wMCs1j\nSHel0e2NY27ycs5tZ7Nt6WpGZ55Fl3UX67Zs4rrJk2n1Rujb3Yytq49sey726RVkObvpb0nDYc5g\n/+q19C3txl7hI81dzN4duxg7q2y4q0bTtNNMSnRfEBaq9+1i0b7NxGMWdlXvINpTy7yzL2Nt63Iu\nO28O1W9v5u4f3Et50Qhycoooycuju6mb9tg+lr61iXDrPq76yPns794JRZW02xNYnBYyrBks2vkO\n+7uaef7dx0gvy2R/WgOTPEW0drTSn20j320nf/xE6r0WLpl4JeMLMsgtCA93rWiadhpKiaDcETIR\naulkXEYe7y56gn3VqzBHmnh14QrqFu3gI5/7BHNv/Bg/v+dHxM0eInVb8bd14Aq1U2pP58ILppDw\n+Vhfv4GedY001u5hw7KlZOVNY8SZZfh70snvy+fy864ikxiRHlhbu5Wd28xsf+Qdnn/jRVbWbOQT\n829iy46VBLwOXnrs2eGuFk3TTkMp0X2x48Wf4x2RT2Sdn0KbmXjbWvw7G1AjuqicUUxWz0j699YT\nmXEm+7auoXpVI++seJTJM8fQbY4RsaRT4GwgI9DLnoY+ymYX0t8/ArurEUdvFueMquT5umXs/ftK\nGsIhbrj1eurXV5HmCrO2N43iSAR3c4y8ihjeiZew4cln8EcyhrtaNE07DaVESznmCNC6dBevvfI4\nUtZPKGQhY95MphVMYcGbVfR1dlNTvZ5I1SI6u7qo3b2Lq6+ciUdlULcnjDUU4oIrP0mrLwcJt9LX\nUENlaTFNzX662zKo7q7n7MrJnPWxi8nLiLLqn+/Sk9PMnqoGJp4xlqzpc2lKC/OXnzzLSy88SSA9\nixJ3x3BXywkhIkpEfj7g9V0ics9h1rlGRMYfJO8eEWkQkY3Jx4+PQxnnisjLx7odTTsZpERQXr1u\nL7nTPIycPQG64mTEzIwL9VF6dh5nnTORcJMft8/E2m1VNKyv4sOf/zye3FH4sRLcs5rSvFI2r1pP\nZqNi4pyLiDS6GZufxqjSM+hr281jCxeS2xAlEOlgyrlXEHO34rOUkF9kwuPuwlSUxyev+iiRYhuq\nI0R2LJdXn3xuuKvlRAkD14pI9lGscw0wZFBO+uWAyVO/eWzF07TTS0oE5Vk5MyCcIBEGc3+CHkec\n5WsX8saCFVw472zU6Hz+9vQylM2HM8+GozCEOdrBlh1vU3rmSMy2VtoDXZSXZrB3y1qyKkK8uGwN\nj778O5r27UY1NXDV7Z/D2hjCoixkFFjIso6gfP5nKR5zA2U+K5s3t1JsTqMhlqCvejUz590+3NVy\nosSAPwJfG5whIuUi8raIbBaRt0SkVETmAFcBP022hEcdyU5E5AIR2SAiW0TkIRGxHyb9UhGpEpH1\nwLXH7d1qWopLiaC8aMc7xKI5BDPNJNJirN26gmmXXEr6hAp2bazCFoDJl3+I+pooZGVgMwUR8vC5\nFDlZpYi4mDPxDJo7/LSZg7z89i7efuUZtq/bzIJXF2F2FfHf936Lnu4oDd19dPR48fk3MnlaOg0b\nX6AwJ50sSw6xhJtQdw79I8qoVVXDXS0n0m+Bj4tI+qD0XwN/U0pNBh4HHlBKLQdeBL6RbAnvGWJ7\nXxvQfXGJiDiAh4HrlVKTMM5l3HGY9D8BVwLTgfzj/YY1LVWlRFAuzu3BlJ5OiSqja1cDn7ntdpYu\n3EJWnSKnohCTCLnZXTTEN1GiClj77kZq9u/g1TfWsX7bEt5cW83CrSvZ1VZD9RY/bo/1/7N3n1Fy\nHOeh9/9Pd08Om3MEsMg5EARBigRISiRFRUoWSdFWuJRpy1fBupYsOVzbx9fyq3tl2UpWoCwqR8oS\nzSRSEkEQYEYkclrsLjbnMHmmu+v9MCN5DZMIJLg7IOp3zpwzWzXbXf2cOc/WVndVMf/ayzGDpdQv\nXc7c6zaQKAnR+vZ3QWkTd/3VF+iMh3j0L7/F8ivbiJqK8rkuhpqiKZSi4+QETXULZjssM0YpNQV8\nF/jIaVVXAD8svP8ecNU5HnL68MWjwEKgQyl1rFD/HeDqM5QvKpQfV/lNJL//YicRkbtEZKeI7Bwe\nHj7HpmlacSuKpLzyjXeAMYqqD9HSPAdnapy21VcwZdkEog2YTglXz1lMJNzGqB1Eypbwjte9nnu+\n8lUaG5cSd9vpOhijvqKMkrIUyxZYbF56Fa9/yyd55yc/QVP9NTTUryO9Zztvu2EdA67DFR/4E4Kv\nX8g3vvBvbHlsF19/8H6qa0NkR4a48/a3UZoLz3ZYZtrngTuBi2bRD6XU3UqpdUqpdVVVVbPdHE27\nIIrikbjOoW5aR21CN3roPtpHOuPDTfQwUdfId775NZaVLuKnT+5izvJVzLGSdOx5lq70eh555mFu\nuGw1HSVXsPZd8whPLWDemlIO9OfIRgIs3jCfgQMHyYx3MGf19ZRd8+ckcimMPccYnBhgbuV85r7r\nrwm11fD22uUcfu7nbH7v1QyVVjJ/3dWzHZYZpZQaE5Gfkk/M9xSKnwZuI99LvgPYXiiPAZHzOPxR\noFVE2pRSJ4A/AJ44Q/mRQvm8wvDI7a/s6jTt4lEUPeWNvrlYdUF+dPcDbFx7Aycm+yDrMrljP8uq\nq3iqbyfO1DjVsRxxL5T56ti9fxdXrtnMI8d2c/stb2fDks1E1jRQV3kZkoYFy2sYONRHr0RYdsUS\nOodGcd0gzx94DGf/C6xdvZq+cYfGlix1tR4GRkapXbeckuw83IkkJZlLcunOzwHTn8L4MPB+EdlH\nPmF+tFD+Y+AThRt0Z73Rp5RKA+8H7hWR/YALfO0s5XcBDxVu9A1dmMvTtOJXFD1lvCMsaZnH4ASk\np9IsKW/GbIswseMFfI3z6H9uD3OvmUtPNsDCYDkTi3oIEmH0ZD93vvt/IyUB9j1+nDa/j4FDp9i4\nqZGaxgXsGz/KvEApjXMgPtLF4LPfZF3TSuTKVp7reo61dS1UNSXZ+/AvCdYvpqVmNYMlJ2htvoGD\nuftnOyozQikVnvZ+EAhO+7kLuPZFfucpXuKROKXU371E+WPA6vMof4T82LKmXVKKIimfykJ5Ikuy\n7yhHM1PknCCtpXOot6N0HNzN/PpV+GIe1lWOsGfPAIuWLsDXupa6OQvozxlUjYeoL4O+kiE6DzzL\n8WfLCHvqaFJVVJTaPPHkLhiapLK3h8a2Tez5zf3sm6ggvfJ5Us/0svfgYSLjOdqf38KGD/wFU72H\nsNvH8/f9NU3TZpDkb25r2sVNRGLkx6i1l68SGJntRlzEzha/FqXUWe9IF0VPWdMugKNKKb0zwSsg\nIjt1DF++CxW/orjRp2mapuXppKxpmlZEdFLWXivunu0GvAboGL4yFyR++kafpmlaEdE9ZU3TtCKi\nk7KmaVoR0UlZu6gU1lk+KiInROS/LaAveV8s1O8TkTWz0c5idQ7x2yQik9OWXv2b2WhnsSqs+T0k\nIgdeov4Vf/90UtYuGiJikl/7+Sby07xvf5FtqW4C5hdedwFfndFGFrFzjB/A9mlLr/79jDay+H0b\nuPEM9a/4+6eTsnYxWQ+cUEqdVEplyS+M9NbTPvNW4Lsq71mgVETqZrqhRepc4qedgVJqGzB2ho+8\n4u+fTsraxaQB6J72c0+h7Hw/c6k619hsLPzr/UsRWTozTXvNeMXfPz3NWtO06XYDzUqpuIi8EbiP\n/NCF5ioAACAASURBVL/i2gzRPWXtYtILNE37ubFQdr6fuVSdNTZKqSmlVLzw/mHAc547nV/qXvH3\nTydl7WKyA5gvInNExEt+V5TTF76+H3hP4S74BmBSKdU/0w0tUmeNn4jUiogU3q8nnyNGZ7ylF69X\n/P3TwxfaRUMpZYvIh4BHARO4Ryl1UET+uFD/NeBh4I3ACSBJfmcTjXOO3zvJ7yhuAyngNqWn/f6O\niPwI2ARUikgP8LeABy7c909Psz5PIvJtoEcp9dez3RZN0157Zmz4QkQ6Cw9dh6aVfUBEtp7j728V\nkQ+cob5VRJSIxKe9XrgATdc0TZsxMz2mbPKfm2++WkqVUuHCa+WrfC5N07QLaqaT8meBj4tI6YtV\nishGEdlRmOa5Q0Q2Fso/DbwO+HKhB/zl8zmpiBgi8tci0lXorX9XREqm1b9FRA6KyEShR754Wt1q\nEdktIjER+QngfzkXrmmadi5mOinvBLYCHz+9QkTKgYeALwIVwD+T32K+Qin1V8B24EOFHvCHzvO8\n7yu8NgNzgTDw5cJ5FwA/Av4UqCI/UP+AiHgLd6jvA74HlAP3Au84z3Nrmqads9l4JO5vgA+LyOkb\nCN4MHFdKfU8pZSulfgQcAd58nscfKfR4J0Tkt8n/DuCfC9NL48BfALeJiAXcCjyklPq1UioH/BMQ\nADYCG8jfWf28UiqnlPoZ+ceKNE3TXhUz/kicUuqAiDwIfAo4PK2qHug67eNdnP8U2UqllH1a2enH\n7iJ/7TWn1ymlXBHpLpzXAXpPeyTo9DZqmqZdMLM1eeRvgT/kvybcPqDltM8185+zYV7Js3unH7sZ\nsIHB0+sKD843Fc7bDzT89mH6ab+raZr2qpiVpKyUOgH8BPjItOKHgQUi8m4RsUTkVvLLCz5YqB8k\nPx78cvwI+FhhJlMY+EfgJ4Ue9U+Bm0XkOhHxAH8GZICngWfIJ++PiIhHRG4hv9KWpmnaq2I2p1n/\nPfC7Z5aVUqPAm8gnxVHgz4E3KaVGCh/5AvBOERkXkS+e57nuIX+zbhvQAaSBDxfOexT4feBLwAj5\nMew3K6WyheUNbyF/k3CM/Pjzz8/7SjVN086RntGnaZpWRPSCRJqmaUVEJ2VN07QiopOypmlaEdFJ\nWdM0rYjopKxpmlZEimKR+4rSkGqoKsNxs2Rci+vWLqZvYoq62kqcdBJfIEIml8Xr8ZHLZkjnhLHJ\nONlsFp/HS85xEVzGJhNUhv3YysUVi5pAimhZGeFgEFGK4fFJIpEIhmWSyzpEIj7GR0aprG3mhRcO\nEPBa9I5M4RWbysoK/n3LXjl767ViUFlZqVpbW2e7GZr2knbt2jWilDp9eYn/piiS8oZ1K2msKqG9\nox3LF2XbCyd5y3VrON7VT3VFOZlMhpKSCMlUingiSV1tLcl0mtGpJF6vH9dxGRmfoLWmnEw2R+/w\nJOmcTXvOpqEixbq1S8mkUvj9QZSTwclBNpthMKGwbZv42CCL2+pIZgWPx086nSaTycx2WLTz0Nra\nys6dO2e7GZr2kkTknJZoKIrnlHdv/YL6yje3MzrQw6LWSnYc6GFkbJIbrlnN8c4e6uoq6OkZwrIs\nqiorcV0X284xMDJBeXk18YlJXFG0n+yisqKUqooyJidiTCWThEMhxsYn2LxhEfFEjkw6jtcSTDEw\ncPF4PEykHMpLguw9cIKxiQxXXLaYh7bvprt/QveULxK+uvmq7r2fn+1maJewzs/cfMZ6EdmllFp3\ntuMUxZjy5z77PdrbTxAMR+geTrF5w2JWLZ3PV77/H9g5m1zWZv7cFvx+PwODg/SPjBMM+GiuLUdy\nk/SOjjM+laCiqpKJWIqO7iGyjsPgeAxTXFobqnnoycNYpAgHfQT9AZTlwTY8xFI5LNPE6/Uyp6mK\njevm4eTirF/cOtthmRGF3Vo+N+3nj4vI353ld94mIkteou7vRKRXRPYWXp+5AG3cVFjEStNe84oi\nKde3tDGnsRpfIEjKFuLJNPXVQe5615uoqasjHk/zwpEOPJbg9/upLgkwMDSKKEUwGGTt4kZO9vTj\nGkI8p3CVy0QsTnk0xOBEmpGJGCGvj8df6Gf73m48XgERSqMhgkE/oVCAoaEhPB4PAKYvRHlJYJaj\nMmMywC3nuY3828ivS/JS/kUptarw+tQra56mXVqKIinH0gaNDbW01IZpqQnT0zeC1zJ5ctcRfB6T\ncDhEdXmUgYEYHssiaUPWhqmsjeu6BHxebrpyKX29w9RWlOD3e0lmHTJpB6+hSGVdHDuFxzTIOvDv\nW48T8UAslSWdzRKbHEPEQEwLUaAyaVzXne2wzBQbuBv42OkVhX0Pt4jIPhF5TESaC7vBvAX4bKEn\nPO9cTlJY8GmPiOwXkXtExHeW8htF5IiI7Ca//oimXRKKIimH/MJULI0hQmlJiIHxJA8/dYyr17aR\ny9kkU1ksy4vH7+VY9xBTU1N4LRgdn2AkFmNgZJRsNsd1ly+gf3AIgKqyMOUVURzlksuk8Xk9pBIx\nUC715SF++fRxVC6FP+DD9AWIx2OksznG4glMjwfbzs1yVGbUvwJ3TN8iq+BLwHeUUiuAHwBfVEo9\nDdwPfKLQE25/keN9bNrwxQ0i4ge+DdyqlFpO/gbzB89S/g3yi0OtBWov9AVrWrEqiqSczTmMZwzi\nKZfYVILl8xuoKovSP5HCwiUa8jI8lsIybNoaKsjZWWzXoLKkBNPwEku75Iz8pVyxqoUTXd3kXEUm\nk8HnsXBRpLM2pZEwpnLp7BvGHzB58MkTbHnmMI6tCJaUkc2m8Hq9jIyN4fP5ZjkqM0cpNQV8l/+6\nlCrAFcAPC++/B1x1joecPnzxKLAQ6FBKHSvUfwe4+gzliwrlxwsbDHz/xU4iIneJyE4R2ekkJ8+x\naZpW3IoiKY+NjBG2FKMTccS08Hk9NNSW0zMa51D3JNv2dtHRN8juYwMYKLyGh+7BIcanUlREQ+Ry\nNsOjMUYTKZLJLFesWYhHFH6fBYZJRXkJiDCZzDCZSBLwe8k5FuURH1MZYduOo2QzKUzDIBTwUhoN\nkctdUj1lgM8DdzJtOdVip5S6Wym1Tim1zgye3snXtItTUSTlhXNr2fLU88RTObbu7uBQxxCpVJJ4\nMsPI+CSGcon4LarKSnlyfzcl0QAtNdXEEkn2Hu5CuQ65rMPoeBzI3wz89Jfu42u/OsA3fnOQLz24\nn+9u6+CHW49yy613IEqRSibpGRzHY0IkHOCJXe0ocXFtB8OwEG90tsMyo5RSY+QX/L9zWvHTwG2F\n93eQ37wWIAZEzuPwR4FWEWkr/PwHwBNnKD9SKP/tePXt53EuTbuoFcXkkcnJGBuXz6VrLEY2YzMS\nzzA4FsdjGqxf3sTY+BR7jvexfvkc+sd87G8foKw0ymQsRcZ2CQR8/J+v/pyK1rmYFriO4LqQyyps\n20XZOcRQGIbFWz/wSd78P/6MbDaLnU7xkdtfTzKdI+AP8fS+IbyGsH5ZLR7jkuspA3wOmL5T+IeB\nb4nIJ4Bh4P2F8h8D3xCRjwDvfIlx5d9RSqVF5P3AvYXNancAX1NKZc5Qfhf53cyT5P8YnM8fAU27\naBXF5JE/+6PfU242zqneUTpH0gQCQaqjfmqrokxNxRmZzNDeM8DChjJO9Axhev2U+SHrCl++dwvB\n0lpEBAeF4zi4OZtcJk1scgw7GcdxsijDh2Hln66wbRvbzpJOxkknU+TsDAvmzeXdb96EQhEJBlmz\nsJKfPLpPTx65SKxbt07pGX1aMbuoJo9kEhOgzHwSHp+ivCyKPxIk5wiRgInrpKmtCFMS8rFqUTNL\nW8oZmkzzrz95iNrSKJnEJNl0ilwySWJshLHBbob7TpGOjZHNpbHtHG4uiZ2awrXTiMrkp1s7ORAX\nV7kcPnac//fVH+D3+JiIp9m64+Rsh0XTtEtQUSRlj2mRSKUI+LzMrzNR6TiSSdDTdQIHYWFLNYlE\ngueP9/H8/hNMJB2+99ATBPwh6itDjPSdZPDUMUYHepiaHCGbSWGY4OAiBohp5HvSrsvAQB/NzXNp\nbW6ltaUFn8+LaZgopUhls3z6y9+lImQRiej/ljVNm3lFkZTjiRS4LmnXS3NjA0saS+geHKS+uRWv\nqUhmsqxd1kIkFKa+qo5P33M/gkHOdvjVkzvI2g7ZXIZUcgInncR1bRwnh2lauG5+eMZRDgMDQ6xb\nuwGPx4NleQj6/MxrncvSRYtYungJhmGQth3+8l++TzIZn+WoaJp2KSqKpFxWUUok7CedSlJWUUYg\n7EcyaXoGR0nnDOxslv6hKVoq/XzlvicwTA8ZO8vg0BC2qxAFIoJpmigBJ5dFKYVSChFwHIeuzlO8\n7qpNGB6LXCYLgOu6KDdDJp3EawlXX3MdmUQc2xG+c9+TsxwVTdMuRUXx9IWdy6Fsm2jAw/BYiobK\nMOVlEcIhk3g8xkQsSzKZJBDwgenFzWZxsjau7SAiKPJJ2TAMlFKYppkfRy5MlbZtm2s3bwYypKeS\n5FwHQymUnSGVyWIY4A+EUdkk6WySQCRK//DIrMZE07RLU1H0lHNZh6zK92jFTjE4kaYkGqY06kMp\nRSaTwu/34YqDYZk4joNleTFNEzEEEYVIvmcMLiqXxrHTdP30YyjXZV5LM5lUnFQihlI5nEwKO5ci\nkYyB6yAKfB5hy5b7KSuvwvL48JhF8fdK07RLTFEkZZ/XwjQMDAOqqirASWFafrK5HNGAQTyVYWh0\nAuWYKEOwLAtbuSAGwm+fWjNwXRcRE/H48QcilN/wt7Q0NQIu4KIcG9MQgkE/Xo/Jbx8HDEcCPLfj\nGUrLGwgEw3gtH2LopKxp2swriqTs9XrJZnPkHJd4PImBAidLOmeQc1xOnBogFI0wmXEJhkx8gTCm\n5UUsE8v0YIgBSjDExDAMcrkcPb09rFm1ClS+J2wZ+TrHccjlclgiBP0eAkEvhw8fJhyK4guEMArH\nte3EbIdF07RLUFEk5cmpOCNxm97hOPFUGjEtQpFSaivL8XkDXLVmLpLLMjUyiOMIhuUhHCnFKCxC\nZBgeRATEob+7i/7BITZftRERhd+bX1jIcRwAlBKUm8NB4Q8F6ezuxRuI4PEIjpNDKYVhgKvMWYuH\npmmXrqL4H922bSrCPhzHwGeZhP0W2WwKsR1CfpO6ylLisUGqyqOQyuK6Bq7r4PMHSas4bjZ/U29o\neBglFkvb5gL53rHt2ogIruuSyzmIKCwxMbA53j5AIFSCYZhYloXpGmSdLKlkiqY6vVqkpmkzryh6\nyulUCtu28Xr92C4Mj08iBrjKJpXJ4rEMykpDjI5PcecNy7GzGRzHxXUVIhaGaWFZFmVhL/WNDbR3\ndfLY408Unke2MAwD0zTxmAYoBwfF4WNdBEKRfEL2eHDFg6MUqWQGj2ly/Yblsx0WTdMuQUWRlEvK\nK0CZKDEZiSWxPCEm41lGJhNkcg6uoyiN+KmpjhJLpnnLZa35JzUcB3EdDFOwPCbBkiqUGFTV1lJX\n38Svtm7jZEdn/uaf5G8IiggHDh7G6wvlbwxiopSJ67oYhkUoFGLZgibect3qWY6KpmmXoqJIysOT\nCUJhL3Y6QX1FEFFp/D6LSMCHTxTZdAon59BYXU44ZFIW8XLHDesxDAuUws7mIOdgiInXtPBZHjwe\nDw119cRTWZ7Yvg3btlFKsWvPbgKRUlwRXGVguw653403OwycPMyH77iZqVh6lqOiadqlqCjGlGvL\nAnQPjFBVUoqdzZB1BCSfJJPp/H55OSW4rkNlxE975wgNtRX8ye9dzdd//hTx2DiucsF18jP5AI+V\n7x37EZpa5tLVN0RifJiq2hZU4W+REhOM/LoYhuvwl3/0dpycjddjYRTFnytN0y41RZGUY5MTRAIB\nhicnifoEv8cim06RdR1M0yCdyxAORZiMxTHFYtncCh7f1cnqhQ189PZrcFyTr/z7M0yMdv/u2WOF\nYBoGeDy4rouFgae6sTCMIYhALpfDwOHOd7w+v+aycgkHvQT8JURC/tkNiqZpl6SiSMqHj/fR1lpF\nachPeWkJYxMJHBRZx8a2c3i8EUbG4/iDQRzbwReIsHFFE5FIGX6Ph4nYJH9663oGxtJYpo9tx9o5\ndbSbqfgkhpmfAaiUwmNZeLx+fOFqbr1uBYNDQ0RDHiIBHxlXAfn1M6YSKXI5Z7bDclESEQfYP63o\nbUqpzld4zK3Ax5VSesFk7TWvKJJyTWUJ41MJolEPxzv78VkupmliGYIv4Gd0YhLTMskk4pgGBD0m\ncZXDtdOMx8ZomdPKA1v2s2xeBbGkza1XLuF4xxhN9aWkMi6WZZLO2YT8PtKZJN39Y0R9QnmJH8HF\nME18Pg9C/jnmVEbhoJPyy5RSSq2a7UZo2sWqKEZO0+ksI6OJ/OQN0yQYKSObc/CHo6QchULAdQiG\n/GRyWRwnR0kkTCaZ4JmDPQwN9jOvqYJAtAylHI51jVJd7gcnRyo5yfDwME4myfjkGOlEmqbqUpQR\nwHBzRAI+vB4TyxtEDIt0OomhcniM2d+R5bVCRPwi8i0R2S8ie0Rk81nKAyLyYxE5LCK/AAKzegGa\nNoOKoqdseTyUl0ZJxFO0ts6lvacXn2kyNDBEMOgj4PdhKBdcheu6uK6L3+shWBvgxoiXZNakPOIS\nGx/BcB3m1gTZ1zlOZdRLOgdhr8V4PJ1/msNrIK7D1MQwgWCQSCRM/3CMkrCXtGtTFo1iWRbxpJ5m\n/TIFRGRv4X2HUurtwP8ElFJquYgsAn4lIgvOUP5BIKmUWiwiK4Dds3EhmjYbiqKnbFkeRkYmGZ9M\nMhUbo6aihLFYhmh5NVnHxOv14hgeUpkMfr8fy+tBLJNUMonp8ROJeBkfi2GZUF9XRsp2mVMTIejz\nU18eIWEbpNNp+oZGyDggpjC3tY7K0gjpZJLSSACvaVJTXoop+X3+Aj7vbIflYpVSSq0qvN5eKLsK\n+D6AUuoI0AUsOEP51dPK9wH7XuxEInKXiOwUkZ3Dw8Ov4iVp2swpip6ybduUlIQoLY0yPDqJ4yos\njzA+Nkoum8MNeLFtG8HBYxoIYIng81h4PSY9A+Mo0yLgscgoExOLkhKTIz0x7Ik4rTUl9NkebK+P\ncDBCMhHDaylQhXUzvH7Kgy62o7AiIVI5l1hc95SLnVLqbuBuyG+cOsvN0bQLoih6yj6fF9d16Orp\noat3lGg4jFeERCaHq1xyWQcxTRCTnGtieUvImQFMXwARoaI0hLhZOvrjTIxO0TcyyfB4ApVNUxky\nicViNFWXknFtBkdHSdpgOy4ej0VJqR9cm5ODyfxynaYf13bwWUXx9+q1YjtwB0BheKIZOHqG8m3A\nuwvly4AVM99kTZsdRZGUR0fHsJWL1xOgJBqhf2CATDqFiODxeFGGEPD5UI6Lk8syNTmCk4njZjKI\nCMGAj6VtDSyfW0YWF0+wjJ6xNOGKavrGU+QcYXgiSUN5GdlslhK/BVYA23WYmMzhMVyCFhxsH8DN\nxQn7PZSXl892WF5LvgIYIrIf+AnwPqVU5gzlXwXCInIY+Htg1yy1W9NmXFF0B7OOjdf0krUz2K5B\n3+Aw85rKKQkFGR8dJxoOEJvKYVkK5TpEQxFclSMcDOG3TDKZFLFkAsvykk2myaViuHaOdDJDOBzG\n8BoYCkIBk+xgllgyg99n4RpCyGcQDFh4vCY+v5ecq0jZDkE1NdthuSgppcIvUpYG3n8e5Sngtlel\ngZpW5IoiKbu5HLGsy/hUAr8HqstCOI7CMAOESyxcJ4ntgm2buK5JLO3gMy3GYwkcxyEa9KPIr4NR\nFgIbPx4xCHlSiGkRDUdIJOJYgTJaqtMobwgxLexMHJ/Pg+XxETIdlJ0ilc5RWuJhcELO3nBN07QL\nTH47LVnTLmYiEiM/Hq29fJWA3jH45Ttb/FqUUlVnO0hR9JQ17QI4qpRaN9uNuJiJyE4dw5fvQsWv\nKG70aZqmaXk6KWuaphURnZS114q7Z7sBrwE6hq/MBYmfvtGnaZpWRHRPWdM0rYjopKxpmlZEdFLW\nLioicqOIHBWREyLyqRepFxH5YqF+n4ismY12FqtziN8mEZkUkb2F19/MRjuLlYjcIyJDInLgJepf\n8fdPJ2XtoiEiJvCvwE3AEuB2EVly2sduAuYXXneRX0dD45zjB7B92vKrfz+jjSx+3wZuPEP9K/7+\n6aSsXUzWAyeUUieVUlngx8BbT/vMW4HvqrxngVIRqZvphhapc4mfdgZKqW3A2Bk+8oq/fzopaxeT\nBqB72s89hbLz/cyl6lxjs7Hwr/cvRWTpzDTtNeMVf//0NGtN06bbDTQrpeIi8kbgPvL/imszRPeU\ntYtJL9A07efGQtn5fuZSddbYKKWmlFLxwvuHAY+IVM5cEy96r/j7p5OydjHZAcwXkTki4iW/5vL9\np33mfuA9hbvgG4BJpVT/TDe0SJ01fiJSKyJSeL+efI4YnfGWXrxe8fdPD19oFw2llC0iHwIeBUzg\nHqXUQRH540L914CHgTcCJ4AkL7KI/qXqHOP3TuCDImIDKeA2paf9/o6I/AjYBFSKSA/wt4AHLtz3\nT0+z1jRNKyJ6+OI8ici3ReQfZrsdmqa9Ns1YUhaRzsJMmNC0sg+IyNZz/P2tIvKBM9S3iogSkfi0\n1wsXoOmapmkzZqZ7yibw0Vf5HKVKqXDhtfJVPpemadoFNdNJ+bPAx0Wk9MUqRWSjiOwozL3fISIb\nC+WfBl4HfLnQA/7y+ZxURAwR+WsR6Sr01r8rIiXT6t8iIgdFZKLQI188rW61iOwWkZiI/ATwv5wL\n1zRNOxcznZR3AluBj59eISLlwEPAF4EK4J+Bh0SkQin1V8B24EOFHvCHzvO87yu8NgNzgTDw5cJ5\nFwA/Av4UqCJ/9/QBEfEWHhu6D/geUA7cC7zjPM+taZp2zmbjRt/fAB8WkdN3db0ZOK6U+p5SylZK\n/Qg4Arz5PI8/UujxTojIb5P/HcA/F+b8x4G/AG4TEQu4FXhIKfVrpVQO+CcgAGwENpB/3OXzSqmc\nUupn5J/11DRNe1XM+HPKSqkDIvIg8Cng8LSqeqDrtI93cf7rFlQqpezTyk4/dhf5a685vU4p5YpI\nd+G8DtB72nOap7dR0zTtgpmtR+L+FvhD/mvC7QNaTvtcM/85RfGVPFB9+rGbARsYPL2uMJupqXDe\nfqDhtzOcpv2upmnaq2JWkrJS6gTwE+Aj04ofBhaIyLtFxBKRW8mv+fpgoX6Q/Hjwy/Ej4GOF6aVh\n4B+BnxR61D8FbhaR60TEA/wZkAGeBp4hn7w/IiIeEbmF/PKHmqZpr4rZnDzy98DvnllWSo0CbyKf\nFEeBPwfepJQaKXzkC8A7RWRcRL54nue6h/zNum1AB5AGPlw471Hg94EvASPkx7DfrJTKFtacvYX8\nTcIx8uPPPz/vK9U0TTtHepq1pmlaEdHTrDVN04qITsqapmlFRCdlTdO0IqKTsqZpWhEpjkXuRw6o\nsa1bKd+wHOpsyDbS/tQjlBsRyi5fB0Ef3TsepWnh6yE8BO0WLDBID+bwl7dBwoJABjfewXjXOBXL\n1oE5SjZxCm9vBSyE/Y8dYdn1KxjtHKeyKgSSZqhzmOoqL2Tmk+gaJrSgDUIx9j/xGI3RUsqu+n05\ne+O1YlBZWalaW1tnuxma9pJ27do1opQ6fSbzf1McSbmjl7LmRRAZhnQNztQgg0PjRGrnMr5nhLLF\nHppW3QQ9CfCbUGUysfso/nltkO0kxwAeaSI90k7FmsvoPb6dhvkL8UZbSeReIOA2svzaGyF1iso5\nJZBOMt45TtSbAE8byJMwEQCvAVYzlUYzR545whVXzXZgtHPV2trKzp07Z7sZmvaSROScZgMXRVKO\nTxp0nDqJ73gVC97YyMHD32XjpnfTuX0fDatCYC2B2G56xhI01lxFduQJSlsbIOQn2T0B3jAezymC\n4fWQ3EFNsAyyOcgcJxQpzJbOJunsmqR17hwgS9m8xTx/9z1cdlMlouoJVZ5k+zdfoH7ufOa9bhN1\nlYvP1mytiOzvnaT1Uw/NdjO0S1jnZ26+IMcpijHlZEMzYycFf7/Blq/8khqphYiitaGS/3vPp/nM\nB7/B1KE0jfNLUKlDeKNl4BUYKiWeOkCw1mCqS+jufQj8yxjuLue5h54H1QjGAjLZEJhCc+Uormsw\ncKgHpo4zZ91qkiGD53+8g2RFE6/7o/cwb8NySI4x3jk122GZEYWNAT437eePi8jfneV33iYiS16i\n7u9EpFdE9hZen7kAbdxUWC9F017ziiIpV7faLJhr09O3m7VrltN/0AE1ws6OBCUvvIFEVQ+e+jLo\n6EWNhKA0QPp4kv5DR6meswqmUoQX1SPMB7uPurUh2haWMjF5GAwTERPbSmOUr2J06HHinn5SXUGq\n5oQJpepY/7/uIrHfQ/xAku69O6B0FLtm/2yHZaZkgFvOcxv5t5GfAv9S/kUptarw+tQra56mXVqK\nIim7/Vl8dQtY9P476Di6mx43wkfv+DZ7chM0/69rWTi3hRNd7cQz5Rgt9eAk8dctpm6VD5U1oczi\n6H17qW6eD7YPNXGSijlRSqs2gjGJ19eLUvvBDVBWW01bZBNT4wMc3j4M6S7Gj9xP1fU5wgurcBJl\nMFiJ3Z6d7bDMFBu4G/jY6RWFLba2iMg+EXlMRJoLGw+8BfhsoSc871xOUlhbZI+I7BeRe0TEd5by\nG0XkiIjsJj/VXdMuCUWRlNUJm107n+Kb//wtGi+fx9TQca57w9Wc2r+Xx+59jrjdSvtIjnufyzJy\n+D84+tQpxgcOM3DAQsQAu4bF1zbh8SRIpsYZibkw5YOJCYifZOCEjac/Ap4sVrof6kqY7B9g8cZV\nTPXMZ2rADwNx4jsP0dxayRNP7qRu86LZDstM+lfgjum7sRR8CfiOUmoF8APgi0qpp4H7gU8UesLt\nL3K8j00bvrhBRPzAt4FblVLLyd/L+OBZyr9Bfh2StUDthb5gTStWRZGUj4+eYsXlm1j7eh+fp6dw\n+wAAE8tJREFU+sn9mM0t+CvSLLzjMqLlKZbUmHR1jTNYOskn/u/DLLxiGZG2CqYiz4KUkBs9ClYC\n10oT9IUIVFhQ2QKVJlnxUNs2H5IOpLtwJpfSu+8BFly1huN9fUSDo2SO2RALE165iC1bf4ib7eLg\n3l2zHZYZo5SaAr7Lf121D+AK4IeF998DzvV5lOnDF48CC4EOpdSxQv13gKvPUL6oUH68sJb191/s\nJCJyl4jsFJGdTnLyHJumacWtKJJy1BvgVOYg1256Hyt8tXTu34OvciWJrTE+evs6JsePMXXgJL6x\nLkre8R6G9lXx+U99kpJcNahTeCpy4GlDbBfMEIFYEjfTjj3ShTdUm+8xty2BIR9mWZjqFZsgnWW+\nadObTrLgXVdBxdVkn3uGq669kxIFE8O52Q7LTPs8cCfTVu4rdkqpu5VS65RS68zg6Z18Tbs4FUVS\nrl+3iIaGtRzfM8LalZdTVrKMnuM/5fIrr+T/fPIbHOxL4ln4+0ztEubc9xT3/+Tn1F97NfuOj0A4\nDNnFIGmMiA1EMRtrMTx+Dh8Zze8dEnDBPQR1YdJ2H5mDRxg82Q3hVhrWXMHY4ZMQ3M5RG5K9h1nz\npj+npeblLt18cVJKjZFfW/rOacVPA7cV3t9Bfp9EgBgQOY/DHwVaRaSt8PMfAE+cofxIofy349W3\nn8e5NO2iVhRJecevH6FkFA71PUJpNkGwrJye4cs5OdlB6bUtzFkSYfLg8/S5W4gsm8uIOcGcVDN7\nnu3DnurGSZwieaobJAkBwU0eAWOM5ZuaSB7vxx2JglXJyLGT+LtMwuEAR7tG2PPkQ9B3glMjL8CY\nheruxZtbDYYw7AzMdlhmw+eA6U9hfBh4v4jsI58wP1oo/zHwicINurPe6FNKpYH3A/eKyH7ABb52\nlvK7yG+cuxsYujCXp2nFryjWU/7Ke/9RLW8t5crNV7BjdIR1q6p4cscoP//5v3H5/PVENtSTfOwQ\n43YzvVXd3LqihcnSIH0PbKViAVx77ZUw3wS1hERvD6FIFKIug88foKK1Fqs8THZqCK93Lc6RScwl\nMZAWyFmQ6wC7EnoH6T55iOxwEOtdzbSk50HTAj3N+iLhq5uv6t77+dluhnYJO9vkERHZpZRad7bj\nFEVSPvD5byhfmx9P0mHXQBn++iFuXtDEeDTAiV8/TXDxen71iwc49cwUQxVZ/vdHP0pt6SClc+og\nYMPUk6RPVmL7XcKLfRx6/DBLNi+CxHyICk7PCcyoAisJw00w4KLK43Qf66V54yJyh3w8fuABFgU3\nMZrrIJIO4du0gKZVV+ukfJFYt26d0tOstWJ2rkm5KIYvOlIZ5q95B+rwONc3KVqNSmiroqyxjvuf\n7efoI8dYcdV8Ft/wLtrqSvlN+z5Kl9Zx4Pu9TPU8w+RxD/5lC5DIFLHRKpa8cRWpkwaovZBJc2hv\nOz17HbIDdYwOdNJDF25tGTFPFX07JvE0pLh29YcpqcqweuHrCc8L0DTime2waJp2CSqKpLx5aQuJ\nbY8wZkTwl3ZR25YkNnCCzm8Ocstb38Wqm9cT9vrJ+DoZT5QwkOjlxLb7WfYnDoybJPoj4E6Q8ZQS\nKSun/ddPEpg3DlVRup44xvLrVtO4sh5veJCKinIUaQZO7GTpojZ6p4YZ6ovjhI7w0FMHoCpK7epV\n0Bqd7bBomnYJKoqkPDwySXf/MRLY+C5fRd8Tp+h5Nk3lHSHiviTPfOfbPL0/R6imkWVL2/iLt1xJ\ng9nAWHuW3+zopPwqD/u2P0q5BHn8Gz9gKlWDylTy9M92UL2oFCdt8MIvfw3OTRCL0FR9LQ1LroZy\nm8xIN5XV5fhyray7Yj6ktxPrc5g61j3bYdE07RJUFEm5Y2ea4z6XpVcthLgf0y1hwk7j9KdZ7ne4\n8Q+vwOt12ffg16mKekkPjhNofCPlNT5uuf0W/JFWVrzhdgi0svn6a3HinTBo01LnEAjWYI5nWTl3\nBUeffo7Bzn5wj8NolPYHXqDF20hfxyD3P7uFBevq2fWrfkIjRzg0vHW2w6Jp2iWoKJJyy2phOWup\nWJKGQIIlf/gnTPi6efLwozy6fwsVagWR0T7e/vo7ePvrllHRcCXUDjPwVIZju3bz/L//jK59T0My\nC/E0zfWldHfupmHRUug/Rs++HVDfxsLGRqbCvSQ7BSZHab18EksMfAxRN9LNth/vZu2dG8k0NbDe\nWTPbYdE07RJUFEl5bGwUW/nBrOHA3Y/Rm3iGkvJylpw0WLxkNc//5ofEcw5PPLcTAt3EDz8AYxFq\n581lQdvVrP+99xAID5KhF5pMjOAYkehiyDk8+8SznJyMcuL+R7n3vn+iyddIsHoO1FiMDOeo+8Bt\nGKcqSC2toGlhGFwfJ3/zPMachtkOi6Zpl6CiSMrzo4tpu6aZ5OPPM2fFIhrKA6zd8FbsN11B86Ic\n4i7ilrdtZuNb/ZDNEF5zJRgHeeGZLVA3AkMTeHJr8A5nefiRR6gMraGsrY7kyCmWrl/DitXrmYyO\nc+0V1zLoKNoTW0geO4TdEeP7/99neM63m/rBWmrKG8k8285Ypp9tg/tmOyyapl2CiiIpu2URntv6\nC4Ibrie0YSOMjuJzhqnIDXLswW68C8Z56jfbuHz+Wjr2JNj/m29BpJRFc14P/RH+43PfoqxmOdKY\nY+OaGxifCkEgSXpgDt75FunkKFXLbyBUt5FTO5LETgQ58sg48SMBbtv8Di5bfA2V84IMDp/kWF+c\nlsXXsGTp+SwvrGmadmEURVIuf/N8Lp+/ma3f+RGT/cfJqnLGBuNM7vKwZPkmVm5+PzctXkdkIkrt\nYj+1K0s5uXM3jjUJoQne+oZr2PEvX6c/XU4ulsQzYcBIHeUb6/GVLiUT7sefCTK589d4q0vY76nE\n+4GreLZWcfDxexjcmyUwVsb+kzsZmdzBlqNfJxcfnu2waJp2CSqKpEwGuKyKTR+9g+HRHry+GkJW\ngDkbQkz4joLdz1h1FSwe4kjns/T2KlqbbyZZsRsMgcuXctnH7qQuWEtV6xWEr60n1n6MwZMT7PvC\ng5Rlgxx++Ov01C7g8Mg4Cyc87PrCz9h02Xw6nDk0e2wS82M0lday+aY/pnHBCnyJptmOiqZpl6Di\nSMqBBjoHHwFCtF3xJojG8VVH6FDDeOLNPPfzB/CmeyE7h9VvfTeLFm8kk3mASu98OrYdhqlTpAdH\nIH6Ck89sgV0JntrdSU3DYlbctJ6cp5p1v7+RU88+RzBykh1bH8deHubx36SoqQjyaCxNZ7sXc/4y\n2mP7iD5dxiNP/3K2o6Jp2iWoKJLygYOP0tKwFkI2yYGjJPpGGDwyyZzWm6hZt4hw1EP12jZyvUn6\nftNN7vhJ7LJNpCayzLn+ZrIHbUwnwTO/7sIOxBhN2Nx41UaOff8JaG4k0zlGqHoNvtIEb7pmJXNX\n1lHrD1MS8+NNmKxtShKRYZ745q+Zt7Se1pVLePdH/ni2w6Jp2iWoKJLysnXzEKsSbJtgbROWz4Wc\nQPYkZOL0bNmPGncYSyWpv6KSg+0DHH76fgJViuSBf+NAcoDjnSdY0bKABeZyKmImv9r+CAPJdthZ\nRn1rGySEBcGFZA77SCUn8O0MsmFTA7tKgzznhIiZdcAKDj1pcdyYoqPvklvkXtO0IlAUSTnV6wOv\nYnw8DW4pvuBifBURCEX54Y//nRvedxsST2LsGWf/15+hyRTWX78JAssI9q0jd2gQc2gMKzzIEx33\nMVjZxxve/z5Sc1roHN/LyePPM97pwT+ngSdOHGHzzZtoWjCPof40KyYruCxRQpVvEt8KH8/2niQa\njrHz/hdmOyyapl2CiiIpB6orSaZNyipCqNEpYrEOjp54DmdklHXXvRGuXM9UTYLhyxNMrQxjLV7J\ntkfuJdG9j18c28rlN72Xhdffhm9kLVb9WmqWX8PBJ7/BDeElHN7yIBVBId17ksmdnTRtWMl4xykW\nvnEZOdXIoKedtkWVuHYplasXsvdEOy90DHDtpnPdjk7TNO3CKYqkjD1A0OwnMTyARMNEKhZy+c3r\nMUMLcWJ9DPaNYHvaaFv1Lq686hbU7jRXv/M9TJw4yYLmJsazP8Wt7MGJt7O6xqX30T3UqFU80/4L\ngg1zKSm5nH1Tx3lufJyB7nEChNj3s3/B6O2gbcKGbICkBBj+wWNc3rqEVt8iTgQuyZ1HXjERcabt\nZL1XRFovwDG3ishZ16HVtNeCokjKU+OT2J5FeKMNoIbBMw4jcezYKItXvZ7KSouSynqyQ7Bv30ms\nq9Yyui1BZP48hlxFWfO7MYaymHdcw95jfhqumUvlhpvI5mqonmOwdcfPqHZdgsODtOQWcrSnEjfS\nSpeqQm0oIRPNUV7awRLzeqoCJj2hZ4nv6J3tsFysUtN2sl6llOqc7QZp2sWkKJJytLYEa+oUqakx\neobHAIHkMoaGRnBSSUyviSs9BGptVly+kcplObLz5sHqJhZVNbNn+y8h08Cp+/+DbK/Fvgfuo/3o\nQZrqotTmlrK0JcSu5w4zb+MaptwjVM/NsmjVciqWHGPbqQT7Drk80xlm0nyByxatxNe/mth+vYvF\nhSIifhH5lojsL+zrt/ks5QER+bGIHBaRXwCBWb0ATZtB1mw3ACA5kiBYLYTsHFGjBRJTuI0J6tON\nEPSglIuHRrAmwAasBurmZUFKid64gLqBPtgzRHjpfDaFyzi6yyaxfx8Lm0s53LeTXPVmPvC1d/Af\nX91OpFEYfPIUn733IW6YfxWV9X5inpPMb5nDvA1v44cPPsSbL7+C9Or62Q7LxSogInsL7zuUUm8H\n/ieglFLLRWQR8CsRWXCG8g8CSaXUYhFZAex+sROJyF3kN1ilubn5Vb4sTZsZRdFTDpaFUSmXiRPH\nwXFITWQwjDkQDAA5JA2ZZI5cNosyU6AEXB+QAyMK9bVwTSvOsS72HnuMPm8X/Z5Bxi0HiW6gjBM8\n8g/f582bl7DlW4c4UB7jhuBbaJvbRPKFY9RYfhL79/C5b/4je3YdYSJk8OD2ntkOy8Vq+vDF2wtl\nVwHfB1BKHQG6gAVnKL96Wvk+4EVXh1JK3a2UWqeUWldVVfUqXpKmzZyi6CmrVBgJleOEHHIpP4PD\nQzQ11GOm61FMIgEvPjcLhgH0o2hATBeVSaOMSQwM8NZSccONeNtP0Do8QDRZSiYZYsD/PAd6UgTe\nUMrPv3wvf3zdNTj1rXTzLEM9g1x/81UcPOhSueQ6rmUllfMqmRjqpjw2Ntth0TTtElQUPWUxT4Az\nRnWwDo9X0bpqJX3tJxgZOw7eABACIwh2GSgXF5tMegTH8eCYCmVkwFIYlqKkZS7R1fM4Xt/OPT/+\nAc0lK4gl5rOkfSk3f/IfaNy0iP27niLnVJNZ+zp+6Q9Qv7KaFKNMLs/xlL0Xf8kEIb1K3IW0HbgD\noDA80QwcPUP5NuDdhfJlwIqZb7KmzY6i6CnjWwDigzIH1FGYrMNbXUVlpARFFpsxLKcMLAuccsQZ\nweerBpkCAqiUgkAXqGawLNycyfx5b2fhX9cRkwa8hw7yb7/ZxuW+UUpORemrq2dpysRzwqXn54/x\n/DvbaEnV46+xiXpb6D1wDGe8fLaj8lryFeCrIrKf/F2B9ymlMiLyUuVfBb4lIoeBw8CuWWu5ps2w\n4kjKEgCzDwgycLKc0uAoNbUWuBU4mRSmmQHLD5wkRy22DQHvKIn4JKGwgfjKwB0GusFqxgiHcDnO\nYL8QXTnAqnmLaStdyPbnfsm86hbKDjewd+xXbLr1zZRePY+u0iqW3djEE888xZzOSfZ4e3nvTXo3\n65dDKRV+kbI08P7zKE8Bt70qDdS0IlcUwxeYY+SSGZykj7JKE9NTAW6EU4f3YgUyiFUGxgC5dBke\nsQgEI0xNOITMRjKZAbBH2ffUccaOB4Ecx/c8jkUzJfNWEBuZ5Ei8mxf6n+aP/v/27t81iiAM4/j3\nIcTCSiFI/BlTXBPBwiKoVcpcmhQKaqGViIKVlSAoWPgHiKKkCGJjwEZTROwkWghKCtEiENIYESQW\n0aAQIq/FLXIcMXfJhr3Z3POBg92dKV5ehpfd2Z25U3dY7NvDzt0rnL93kVfTM+w7epjeP8uMjz2l\nMnSC/mtnqA7f4M3z+XZnxcw6kCKi3TGY5SbpJ7X5aNu8HmCx3UGUWLP89UVE08+E0pi+MMtvNiK8\nFDsHSe+dw83bqvylMX1hZmaAi7KZWVJclG27GGt3ANuAc5jPluTPL/rMzBLiO2Uzs4S4KFupSBqW\nNCtpTtL1Ndol6W7W/kHSsXbEmaoW8jckaanuTwputiPOVEkal/RN0sf/tOcefy7KVhqSuoD7QBUY\nAM5JGmjoVgUq2e8S8KDQIBPWYv4AXtft9He70CDT9wgYXqc99/hzUbYyGQTmImI+IlaACWC0oc8o\n8Dhq3gK7JO0tOtBEtZI/W0dETAPrbSGZe/y5KFuZ7Ac+150vZNc22qdTtZqbk9mj9wtJR4oJbdvI\nPf68os/M6s0AhyJiWdII8Izao7gVxHfKViZfgIN15weyaxvt06ma5iYifkTEcnY8BXRL8ubircs9\n/lyUrUzeARVJ/ZJ2UNvec7KhzyRwIXsLfhxYioivRQeaqKb5k9QrSdnxILUa8b3wSMsr9/jz9IWV\nRkSsSroKvAS6gPGI+CTpctb+EJgCRoA54Bdr7NfcqVrM32ngiqRV4DdwNrzC7B9JT4AhoEfSAnAL\n6IatG39e0WdmlhBPX5iZJcRF2cwsIS7KZmYJcVE2M0uIi7KZWUJclM3MEuKibGaWEBdlM7OE/AUJ\nAMiUCJXFWAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x122016cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Display Image Predictions Complete\n"
     ]
    }
   ],
   "source": [
    "save_model_path = \"./training_sess\"\n",
    "n_samples = 4\n",
    "top_n_predictions = 2\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for test_image_batch, test_label_batch, test_path_batch in get_mini_batches(batch_size, test_images, test_labels, test_paths):\n",
    "            \n",
    "            transposed_images = np.array(test_image_batch).transpose(0, 3, 1, 2)\n",
    "            \n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: transposed_images, loaded_y: test_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_images, random_test_labels = tuple(zip(*random.sample(list(zip(test_images, test_labels)), n_samples)))\n",
    "        \n",
    "        \n",
    "        transposed_images = np.array(test_image_batch).transpose(0, 3, 1, 2)\n",
    "            \n",
    "            \n",
    "        \n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), 2),\n",
    "            feed_dict={loaded_x: transposed_images, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        display_image_predictions(random_test_images, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Woot! This testing accuracy is 8% higher than my previous submission. \n",
    "\n",
    "Although I could not get display_image_predictions to function, it was intended to display a few random images and the model's associated probabilites for each class in a table format. However, looking at the testing accuracy, the model's prospects look encouraging. \n",
    "\n",
    "### Goal 4: Testing the Network on Local Machines:\n",
    "\n",
    "Running the following cells will allow you to input the file path of an image, and the model will provide you with a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sarahhernandez/Documents/4. Important Docs/Passio/tissues.jpg\n"
     ]
    }
   ],
   "source": [
    "# Enter filepath of image\n",
    "input_img = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Enter 0 if it's Not Food, 1 if it's Food\n",
    "input_label = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "single_label = []\n",
    "if input_label == str(0):\n",
    "    single_label = [1, 0]\n",
    "elif input_label == str(1):\n",
    "    single_label = [0, 1]\n",
    "else:\n",
    "    print(\"Invalid label input, please run above cell again\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./training_sess\n",
      "Testing Accuracy: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(input_img)\n",
    "img = cv2.resize(img,(256,256))\n",
    "img = normalize(img)\n",
    "img_stack = [img]\n",
    "label_stack = [single_label]\n",
    "\n",
    "loaded_graph = tf.Graph()\n",
    "with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "       \n",
    "        transposed_images = np.array(img_stack).transpose(0, 3, 1, 2)\n",
    "            \n",
    "        test_batch_acc_total += sess.run(loaded_acc, feed_dict={loaded_x: transposed_images, loaded_y: label_stack, loaded_keep_prob: 1.0})\n",
    "        \n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total))\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wonderful! If the testing accuracy is 1, then the model correctly predicted the given image, if the testing accuracy is 0, then the model failed to predict if the image was food or not food. \n",
    "\n",
    "\n",
    "### Future Work:\n",
    "\n",
    "For further improvements to the program, I would implement the following:\n",
    "\n",
    "* I would further expand the dataset by randomly cropping, translating and scaling images, or by using an online dataset\n",
    "* I'd like to see the results of implementing a k-fold cross validation, as it's good to use with limited datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
